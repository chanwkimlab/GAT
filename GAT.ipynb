{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "import socket\n",
    "\n",
    "\n",
    "from pyplink import PyPlink\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#jupyter nbconvert GAT.ipynb --to script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--condition-list'], dest='condition_list', nargs=None, const=None, default=None, type=<function file_path at 0x7f64643bd598>, choices=None, help='format is the same as plink', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dir_path(path):\n",
    "    if os.path.exists(os.path.dirname(path)):\n",
    "        return path\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError(f\"readable_dir:{path} is not a valid path\")\n",
    "\n",
    "def file_path(path):\n",
    "    if os.path.isfile(path):\n",
    "        return path\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError(f\"readable_dir:{path} is not a valid path\")\n",
    "\n",
    "def bfile_path(path):\n",
    "    if os.path.isfile(path+'.fam') and os.path.isfile(path+'.bed') and os.path.isfile(path+'.bim'):\n",
    "        return path\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError(f\"readable_dir:{path} is not a valid path\")\n",
    "        \n",
    "parser = argparse.ArgumentParser(description='Multialleic association test')\n",
    "\n",
    "#required mode\n",
    "parser.add_argument('--assoc',choices=['linear','logistic'],required=True)\n",
    "\n",
    "#required output file\n",
    "parser.add_argument('--out', type=dir_path,required=True,help='output file prefix. (prefix.log, prefix.assoc will be generated)')\n",
    "\n",
    "#required input files\n",
    "parser.add_argument('--bgl-phased', type=file_path,help='bgl-phased (See Beagle 5.1 documentation)')\n",
    "parser.add_argument('--bfile', type=bfile_path,help='plink binary format')\n",
    "parser.add_argument('--multialleic',type=str,help='regular expression for specifying multiple alleic marker (comma delimiter)')\n",
    "parser.add_argument('--multialleic-always',type=str,help='regular expression for specifying multiple alleic marker (comma delimiter)')\n",
    "\n",
    "parser.add_argument('--pheno', type=file_path,required=True,help='format is the same as plink. Tab-delimited file without header of which the first and second columns is family and within-family IDs respectively and the third columns are pheotype')\n",
    "\n",
    "#optional\n",
    "parser.add_argument('--covar', type=file_path,help='format is the same as plink')\n",
    "parser.add_argument('--condition-list',type=file_path,help='format is the same as plink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug=True\n",
    "#debug=True\n",
    "\n",
    "if debug:\n",
    "    arg_split='\\\n",
    "--assoc linear \\\n",
    "--out data/out_assoc/ALP/step_01 \\\n",
    "--bgl-phased data/genotype/4_merge/KCHIP_HLA_AA_SNP.bgl.phased \\\n",
    "--bfile data/genotype/4_merge/KCHIP_HLA_SNP_1000G \\\n",
    "--multialleic (?P<name>HLA_[0-9A-Z]*)\\*(?P<allele>[0-9:]*) \\\n",
    "--multialleic-always (?P<name>AA_[A-Z0-9]*_[0-9]*_[0-9]*_exon[0-9]*)_*(?P<allele>[A-Z]*) \\\n",
    "--pheno data/out_pheno/ALP.phe \\\n",
    "--covar data/out_assoc/ALP/step_01.covar \\\n",
    "--condition-list data/out_assoc/ALP/step_01.cond\\\n",
    "'.split(' ')\n",
    "    args=parser.parse_args(arg_split)\n",
    "else:\n",
    "    args=parser.parse_args()\n",
    "    \n",
    "if args.bfile is None and args.bgl_phased is None:\n",
    "    raise argparse.ArgumentTypeError(\"either --bfile or --bgl-phased parameter is needed\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger('logger')\n",
    "log.setLevel(logging.DEBUG)\n",
    "\n",
    "log_file_path=args.out+'.log'\n",
    "fileHandler = logging.FileHandler(log_file_path)\n",
    "streamHandler = logging.StreamHandler()\n",
    "\n",
    "formatter = logging.Formatter('%(message)s')\n",
    "fileHandler.setFormatter(formatter)\n",
    "streamHandler.setFormatter(formatter)\n",
    "\n",
    "log.addHandler(fileHandler)\n",
    "log.addHandler(streamHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info_head=lambda x: log.info('*'*int((100-len(x))/2)+x+'*'*int((100-len(x))/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***************************************************************************************************\n",
      "* Generic Association Tool\n",
      "* Description: Generic module for testing bialleic/multialleic phased/unphased markers\n",
      "* version 1.0\n",
      "* (C) 2020-, Seoul National University\n",
      "* Please report bugs to: Chanwoo Kim <ch6845@snu.ac.kr>\n",
      "* https://github.com/ch6845/Generic_Association_Tool\n",
      "***************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "log.info_head(\"*********************************\")\n",
    "log.info(\"* Generic Association Tool\")\n",
    "log.info(\"* Description: Generic module for testing bialleic/multialleic phased/unphased markers\")\n",
    "log.info(\"* version 1.0\")\n",
    "log.info(\"* (C) 2020-, Seoul National University\")\n",
    "log.info(\"* Please report bugs to: Chanwoo Kim <ch6845@snu.ac.kr>\")\n",
    "log.info(\"* https://github.com/ch6845/Generic_Association_Tool\")\n",
    "log.info_head(\"*********************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start time: Mon Mar  2 17:15:39 2020\n"
     ]
    }
   ],
   "source": [
    "log.info(\"Start time: \"+time.strftime('%c', time.localtime(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Working directory: /data/ch6845/MHC_phewas_testbench\n",
      "Hostname: localhost.localdomain\n"
     ]
    }
   ],
   "source": [
    "log.info('Working directory: '+os.getcwd())\n",
    "log.info('Hostname: '+socket.gethostname())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameters\n",
      "--assoc linear\n",
      "--out data/out_assoc/ALP/step_01\n",
      "--bgl_phased data/genotype/4_merge/KCHIP_HLA_AA_SNP.bgl.phased\n",
      "--bfile data/genotype/4_merge/KCHIP_HLA_SNP_1000G\n",
      "--multialleic (?P<name>HLA_[0-9A-Z]*)\\*(?P<allele>[0-9:]*)\n",
      "--multialleic_always (?P<name>AA_[A-Z0-9]*_[0-9]*_[0-9]*_exon[0-9]*)_*(?P<allele>[A-Z]*)\n",
      "--pheno data/out_pheno/ALP.phe\n",
      "--covar data/out_assoc/ALP/step_01.covar\n",
      "--condition_list data/out_assoc/ALP/step_01.cond\n"
     ]
    }
   ],
   "source": [
    "log.info('Parameters\\n'+'\\n'.join(['--{} {}'.format(key,value) for key,value in vars(args).items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assoc=args.assoc\n",
    "out=args.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "********************************************Data Loading********************************************\n"
     ]
    }
   ],
   "source": [
    "log.info_head(\"Data Loading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parse input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125673 samples (45647 males, 80026 females) loaded from data/genotype/4_merge/KCHIP_HLA_SNP_1000G\n",
      "74320 unphased variants loaded from data/genotype/4_merge/KCHIP_HLA_SNP_1000G\n"
     ]
    }
   ],
   "source": [
    "if args.bfile is not None:\n",
    "    plink=PyPlink(args.bfile)\n",
    "    plink_bim=plink.get_bim()\n",
    "    plink_fam=plink.get_fam().astype({'fid':str,'iid':str}).rename(columns={'fid':'FID','iid':'IID','father':'fID', 'mother':'mID','gender':'sex'})\n",
    "    \n",
    "    log.info(\"{} samples ({} males, {} females) loaded from {}\".format(plink_fam.shape[0],(plink_fam['sex']==1).sum(),(plink_fam['sex']==2).sum(),args.bfile))\n",
    "    log.info(\"{} unphased variants loaded from {}\".format(plink_bim.shape[0],args.bfile))\n",
    "else:\n",
    "    plink=None\n",
    "    plink_bim=None\n",
    "    plink_fam=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading bgl phased\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " read 11539 markers"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11539 phsaed variants loaded from data/genotype/4_merge/KCHIP_HLA_AA_SNP.bgl.phased\n",
      "125673 samples (45647 males, 80026 females) loaded from data/genotype/4_merge/KCHIP_HLA_AA_SNP.bgl.phased\n"
     ]
    }
   ],
   "source": [
    "phased_FID_list=None\n",
    "phased_IID_list=None\n",
    "phased_fID_list=None\n",
    "phased_mID_list=None\n",
    "phased_sex_list=None\n",
    "\n",
    "phased_marker_name_list=None\n",
    "phased_marker_data_list=None\n",
    "\n",
    "\n",
    "if args.bgl_phased is not None:\n",
    "    log.info(\"Loading bgl phased\")\n",
    "\n",
    "    with open(args.bgl_phased,'r') as f:\n",
    "        line_cnt=0\n",
    "        while True:\n",
    "            \n",
    "            line=f.readline()            \n",
    "            \n",
    "            if not line or line_cnt%1000==5:\n",
    "                sys.stdout.write('\\r read %5d markers' % (line_cnt-5))\n",
    "                sys.stdout.flush()             \n",
    "                if not line:\n",
    "                    break\n",
    "                    \n",
    "            line_cnt+=1\n",
    "            line_split=line.strip().split(' ')\n",
    "            line_type,line_id,line_data=line_split[0],line_split[1],line_split[2:]\n",
    "            if line_type=='P':\n",
    "                phased_FID_list1=np.array([line_data[i+0] for i in range(0,len(line_data),2)])\n",
    "                phased_FID_list2=np.array([line_data[i+1] for i in range(0,len(line_data),2)])\n",
    "                if np.all(phased_FID_list1==phased_FID_list2):\n",
    "                    phased_FID_list=phased_FID_list1\n",
    "                else:\n",
    "                    raise\n",
    "            elif line_type=='fID':\n",
    "                phased_fID_list1=np.array([line_data[i+0] for i in range(0,len(line_data),2)])\n",
    "                phased_fID_list2=np.array([line_data[i+1] for i in range(0,len(line_data),2)])\n",
    "                if np.all(phased_fID_list1==phased_fID_list2):\n",
    "                    phased_fID_list=phased_fID_list1\n",
    "                else:\n",
    "                    raise\n",
    "            elif line_type=='mID':\n",
    "                phased_mID_list1=np.array([line_data[i+0] for i in range(0,len(line_data),2)])\n",
    "                phased_mID_list2=np.array([line_data[i+1] for i in range(0,len(line_data),2)])\n",
    "                if np.all(phased_mID_list1==phased_mID_list2):\n",
    "                    phased_mID_list=phased_mID_list1\n",
    "                else:\n",
    "                    raise      \n",
    "            elif line_type=='I':        \n",
    "                phased_IID_list1=np.array([line_data[i+0] for i in range(0,len(line_data),2)])\n",
    "                phased_IID_list2=np.array([line_data[i+1] for i in range(0,len(line_data),2)])\n",
    "                if np.all(phased_IID_list1==phased_IID_list2):\n",
    "                    phased_IID_list=phased_IID_list1\n",
    "                else:\n",
    "                    raise   \n",
    "            elif line_type=='C':\n",
    "                phased_sex_list1=np.array([line_data[i+0] for i in range(0,len(line_data),2)])\n",
    "                phased_sex_list2=np.array([line_data[i+1] for i in range(0,len(line_data),2)])\n",
    "                if np.all(phased_sex_list1==phased_sex_list2):\n",
    "                    phased_sex_list=np.array(phased_sex_list1).astype(int)\n",
    "                else:\n",
    "                    raise  \n",
    "            elif line_type=='M':\n",
    "                if phased_marker_name_list is None:\n",
    "                    phased_marker_name_list=[]\n",
    "                if phased_marker_data_list is None:\n",
    "                    phased_marker_data_list=[]                    \n",
    "                phased_marker_name_list.append(line_id)\n",
    "                line_data=np.array(line_data)\n",
    "                phased_marker_data_list.append(line_data)\n",
    "            else:\n",
    "                print(line_type)\n",
    "                raise \n",
    "                \n",
    "    assert phased_FID_list is not None\n",
    "    assert phased_IID_list is not None\n",
    "    assert phased_fID_list is not None\n",
    "    assert phased_mID_list is not None\n",
    "    assert phased_sex_list is not None\n",
    "    assert len(phased_marker_name_list)!=0\n",
    "    assert len(phased_marker_data_list)!=0\n",
    "    log.info(\"{} phsaed variants loaded from {}\".format(len(phased_marker_name_list),args.bgl_phased))\n",
    "    log.info(\"{} samples ({} males, {} females) loaded from {}\".format(len(phased_IID_list),(np.array(phased_sex_list).astype(int)==1).sum(),(np.array(phased_sex_list).astype(int)==2).sum(),args.bgl_phased))\n",
    "    #aa_marker_name_list_aaonly=pd.Series(aa_marker_name_list)[pd.Series(aa_marker_name_list).str.slice(stop=3)=='AA_'].values            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno=pd.read_csv(args.pheno,header=None,sep='\\t',names=['FID','IID','pheno'])\n",
    "pheno['pheno']=pheno['pheno'].replace(-9,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.assoc=='linear':\n",
    "    assert len(pheno['pheno'].unique())>2\n",
    "else:\n",
    "    assert np.all(np.isnan(pheno['pheno'])|(pheno['pheno']==1)|(pheno['pheno']==2))\n",
    "    pheno['pheno']=pheno['pheno']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125673 pheotype loaded from data/out_pheno/ALP.phe\n",
      "Among them, valid: 59469, missing: 66204\n",
      "mean=205.529 std=74.887 median=205.000 min=4.000 max=462.000\n"
     ]
    }
   ],
   "source": [
    "log.info(\"{} pheotype loaded from {}\".format(pheno.shape[0],args.pheno))\n",
    "log.info(\"Among them, valid: {}, missing: {}\".format((~pheno['pheno'].isnull()).sum(),pheno['pheno'].isnull().sum()))\n",
    "if assoc=='linear':\n",
    "    log.info(\"mean={:.3f} std={:.3f} median={:.3f} min={:.3f} max={:.3f}\".format(pheno['pheno'].mean(),pheno['pheno'].std(),pheno['pheno'].median(),pheno['pheno'].min(),pheno['pheno'].max()))\n",
    "else:\n",
    "    log.info(\"case: {} / control: {}\".format((pheno['pheno']==1).sum(),(pheno['pheno']==0).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parse multialleic regular exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***********************************Multialleic expression parsing***********************************\n"
     ]
    }
   ],
   "source": [
    "log.info_head(\"Multialleic expression parsing\")\n",
    "\n",
    "plink_multialleic_dict={}\n",
    "plink_multialleic_always_dict={}\n",
    "\n",
    "phased_multialleic_dict={}\n",
    "phased_multialleic_always_dict={}\n",
    "\n",
    "for expression in args.multialleic.split(','):\n",
    "    re_exp=re.compile(expression)\n",
    "    if plink is not None:\n",
    "        for marker in plink_bim.index:\n",
    "            name,allele=(re_exp.search(marker).group('name'),re_exp.search(marker).group('allele')) if re_exp.search(marker) is not None else (None,None)\n",
    "            if name is not None:\n",
    "                plink_multialleic_dict[marker]=name\n",
    "    if phased_marker_name_list is not None:\n",
    "        for marker in phased_marker_name_list:\n",
    "            name,allele=(re_exp.search(marker).group('name'),re_exp.search(marker).group('allele')) if re_exp.search(marker) is not None else (None,None)\n",
    "            if name is not None:\n",
    "                phased_multialleic_dict[marker]=name  \n",
    "\n",
    "\n",
    "for expression in args.multialleic_always.split(','):\n",
    "    re_exp=re.compile(expression)\n",
    "    if plink is not None:\n",
    "        for marker in plink_bim.index:\n",
    "            name,allele=(re_exp.search(marker).group('name'),re_exp.search(marker).group('allele')) if re_exp.search(marker) is not None else (None,None)\n",
    "            if name is not None:\n",
    "                plink_multialleic_always_dict[marker]=name\n",
    "                \n",
    "    if phased_marker_name_list is not None:\n",
    "        for marker in phased_marker_name_list:\n",
    "            name,allele=(re_exp.search(marker).group('name'),re_exp.search(marker).group('allele')) if re_exp.search(marker) is not None else (None,None)\n",
    "            if name is not None:\n",
    "                phased_multialleic_always_dict[marker]=name\n",
    "                \n",
    "plink_multialleic_df=pd.DataFrame(list(zip(plink_multialleic_dict.keys(),plink_multialleic_dict.values())),columns=['marker','name'])\n",
    "plink_multialleic_df['from']='plink_multialleic'\n",
    "plink_multialleic_always_df=pd.DataFrame(list(zip(plink_multialleic_always_dict.keys(),plink_multialleic_always_dict.values())),columns=['marker','name'])\n",
    "plink_multialleic_always_df['from']='plink_multialleic_always'\n",
    "\n",
    "phased_multialleic_df=pd.DataFrame(list(zip(phased_multialleic_dict.keys(),phased_multialleic_dict.values())),columns=['marker','name'])\n",
    "phased_multialleic_df['from']='phased_multialleic'\n",
    "phased_multialleic_always_df=pd.DataFrame(list(zip(phased_multialleic_always_dict.keys(),phased_multialleic_always_dict.values())),columns=['marker','name'])\n",
    "phased_multialleic_always_df['from']='phased_multialleic_always'\n",
    "\n",
    "\n",
    "multialleic_df_concat=pd.concat([plink_multialleic_df,plink_multialleic_always_df,phased_multialleic_df,phased_multialleic_always_df],sort=False)\n",
    "\n",
    "\n",
    "multialleic_df_concat_notalways=multialleic_df_concat[(multialleic_df_concat['from']=='plink_multialleic') | (multialleic_df_concat['from']=='phased_multialleic')]\n",
    "multialleic_df_concat_always=multialleic_df_concat[(multialleic_df_concat['from']=='plink_multialleic_always') | (multialleic_df_concat['from']=='phased_multialleic_always')]\n",
    "multialleic_collapse=set(multialleic_df_concat_always['name']).intersection(set(multialleic_df_concat_notalways['name']))\n",
    "\n",
    "if len(multialleic_collapse)!=0:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "plink, multialleic: HLA_A,HLA_C,HLA_B,HLA_DRB1,HLA_DQA1,HLA_DQB1,HLA_DPA1,HLA_DPB1\n",
      "plink, multialleic always: \n",
      "phased, multialleic: HLA_A,HLA_C,HLA_B,HLA_DRB1,HLA_DQA1,HLA_DQB1,HLA_DPA1,HLA_DPB1\n",
      "phased, multialleic always: AA_A_9_30018537_exon2,AA_A_17_30018561_exon2,AA_A_44_30018642_exon2,AA_A_56_30018678_exon2,AA_A_62_30018696_exon2,AA_A_63_30018699_exon2,AA_A_65_30018705_exon2,AA_A_66_30018708_exon2,AA_A_67_30018711_exon2,AA_A_70_30018720_exon2,AA_A_73_30018729_exon2,AA_A_74_30018732_exon2,AA_A_76_30018738_exon2,AA_A_77_30018741_exon2,AA_A_79_30018747_exon2,AA_A_80_30018750_exon2,AA_A_81_30018753_exon2,AA_A_82_30018756_exon2,AA_A_83_30018759_exon2,AA_A_90_30018780_exon2,AA_A_95_30019036_exon3,AA_A_97_30019042_exon3,AA_A_99_30019048_exon3,AA_A_102_30019057_exon3,AA_A_105_30019066_exon3,AA_A_107_30019072_exon3,AA_A_109_30019078_exon3,AA_A_114_30019093_exon3,AA_A_116_30019099_exon3,AA_A_127_30019132_exon3,AA_A_142_30019177_exon3,AA_A_144_30019183_exon3,AA_A_145_30019186_exon3,AA_A_149_30019198_exon3,AA_A_150_30019201_exon3,AA_A_151_30019204_exon3,AA_A_152_30019207_exon3,AA_A_156_30019219_exon3,AA_A_158_30019225_exon3,AA_A_161_30019234_exon3,AA_A_163_30019240_exon3,AA_A_166_30019249_exon3,AA_A_167_30019252_exon3,AA_A_184_30019882_exon4,AA_A_193_30019909_exon4,AA_A_194_30019912_exon4,AA_A_207_30019951_exon4,AA_A_246_30020068_exon4,AA_A_253_30020089_exon4,AA_A_276_30020260_exon5,AA_A_282_30020278_exon5,AA_A_294_30020314_exon5,AA_A_297_30020323_exon5,AA_A_298_30020326_exon5,AA_A_299_30020329_exon5,AA_A_307_30020353_exon5,AA_A_311_30020365_exon5,AA_A_321_30020837_exon6,AA_A_334_30021018_exon7,AA_C_339_31345110_exon7,AA_C_326_31345149_exon7,AA_C_324_31345262_exon6,AA_C_321_31345271_exon6,AA_C_307_31345752_exon5,AA_C_306_31345755_exon5,AA_C_305_31345758_exon5,AA_C_304_31345761_exon5,AA_C_303_31345764_exon5,AA_C_295_31345788_exon5,AA_C_285_31345818_exon5,AA_C_275_31345848_exon5,AA_C_273_31345975_exon4,AA_C_267_31345993_exon4,AA_C_261_31346011_exon4,AA_C_253_31346035_exon4,AA_C_248_31346050_exon4,AA_C_219_31346137_exon4,AA_C_211_31346161_exon4,AA_C_194_31346212_exon4,AA_C_184_31346242_exon4,AA_C_177_31346850_exon3,AA_C_175_31346856_exon3,AA_C_173_31346862_exon3,AA_C_163_31346892_exon3,AA_C_156_31346913_exon3,AA_C_152_31346925_exon3,AA_C_147_31346940_exon3,AA_C_138_31346967_exon3,AA_C_116_31347033_exon3,AA_C_114_31347039_exon3,AA_C_113_31347042_exon3,AA_C_103_31347072_exon3,AA_C_99_31347084_exon3,AA_C_97_31347090_exon3,AA_C_95_31347096_exon3,AA_C_94_31347099_exon3,AA_C_91_31347108_exon3,AA_C_90_31347357_exon2,AA_C_80_31347387_exon2,AA_C_77_31347396_exon2,AA_C_73_31347408_exon2,AA_C_66_31347429_exon2,AA_C_49_31347480_exon2,AA_C_35_31347522_exon2,AA_C_24_31347555_exon2,AA_C_21_31347564_exon2,AA_C_16_31347579_exon2,AA_C_14_31347585_exon2,AA_C_11_31347594_exon2,AA_C_9_31347600_exon2,AA_C_6_31347609_exon2,AA_C_1_31347624_exon2,AA_B_325_31430282_exon7,AA_B_305_31430889_exon5,AA_B_282_31430958_exon5,AA_B_245_31431162_exon4,AA_B_199_31431300_exon4,AA_B_194_31431315_exon4,AA_B_180_31431931_exon3,AA_B_178_31431937_exon3,AA_B_177_31431940_exon3,AA_B_171_31431958_exon3,AA_B_167_31431970_exon3,AA_B_163_31431982_exon3,AA_B_158_31431997_exon3,AA_B_156_31432003_exon3,AA_B_152_31432015_exon3,AA_B_147_31432030_exon3,AA_B_145_31432036_exon3,AA_B_143_31432042_exon3,AA_B_131_31432078_exon3,AA_B_116_31432123_exon3,AA_B_114_31432129_exon3,AA_B_113_31432132_exon3,AA_B_103_31432162_exon3,AA_B_99_31432174_exon3,AA_B_97_31432180_exon3,AA_B_95_31432186_exon3,AA_B_94_31432189_exon3,AA_B_83_31432467_exon2,AA_B_82_31432470_exon2,AA_B_81_31432473_exon2,AA_B_80_31432476_exon2,AA_B_77_31432485_exon2,AA_B_76_31432488_exon2,AA_B_74_31432494_exon2,AA_B_71_31432503_exon2,AA_B_70_31432506_exon2,AA_B_69_31432509_exon2,AA_B_67_31432515_exon2,AA_B_66_31432518_exon2,AA_B_65_31432521_exon2,AA_B_63_31432527_exon2,AA_B_62_31432530_exon2,AA_B_52_31432560_exon2,AA_B_46_31432578_exon2,AA_B_45_31432581_exon2,AA_B_41_31432593_exon2,AA_B_32_31432620_exon2,AA_B_24_31432644_exon2,AA_B_12_31432680_exon2,AA_B_11_31432683_exon2,AA_B_9_31432689_exon2,AA_DRB1_233_32656026_exon5,AA_DRB1_231_32656032_exon5,AA_DRB1_189_32656645_exon4,AA_DRB1_181_32657370_exon3,AA_DRB1_180_32657373_exon3,AA_DRB1_166_32657415_exon3,AA_DRB1_149_32657466_exon3,AA_DRB1_142_32657487_exon3,AA_DRB1_140_32657493_exon3,AA_DRB1_133_32657514_exon3,AA_DRB1_120_32657553_exon3,AA_DRB1_104_32657601_exon3,AA_DRB1_98_32657619_exon3,AA_DRB1_96_32657625_exon3,AA_DRB1_86_32659882_exon2,AA_DRB1_85_32659885_exon2,AA_DRB1_78_32659906_exon2,AA_DRB1_77_32659909_exon2,AA_DRB1_74_32659918_exon2,AA_DRB1_73_32659921_exon2,AA_DRB1_71_32659927_exon2,AA_DRB1_70_32659930_exon2,AA_DRB1_67_32659939_exon2,AA_DRB1_60_32659960_exon2,AA_DRB1_58_32659966_exon2,AA_DRB1_57_32659969_exon2,AA_DRB1_47_32659999_exon2,AA_DRB1_40_32660020_exon2,AA_DRB1_38_32660026_exon2,AA_DRB1_37_32660029_exon2,AA_DRB1_33_32660041_exon2,AA_DRB1_32_32660044_exon2,AA_DRB1_31_32660047_exon2,AA_DRB1_30_32660050_exon2,AA_DRB1_28_32660056_exon2,AA_DRB1_26_32660062_exon2,AA_DRB1_25_32660065_exon2,AA_DRB1_16_32660092_exon2,AA_DRB1_14_32660098_exon2,AA_DRB1_13_32660101_exon2,AA_DRB1_12_32660104_exon2,AA_DRB1_11_32660107_exon2,AA_DRB1_10_32660110_exon2,AA_DRB1_9_32660113_exon2,AA_DRB1_4_32665400_exon1,AA_DQA1_2_32713287_exon1,AA_DQA1_11_32717089_exon2,AA_DQA1_18_32717110_exon2,AA_DQA1_25_32717131_exon2,AA_DQA1_26_32717134_exon2,AA_DQA1_34_32717158_exon2,AA_DQA1_40_32717176_exon2,AA_DQA1_41_32717179_exon2,AA_DQA1_45_32717191_exon2,AA_DQA1_47_32717197_exon2,AA_DQA1_48_32717200_exon2,AA_DQA1_50_32717206_exon2,AA_DQA1_51_32717209_exon2,AA_DQA1_52_32717212_exon2,AA_DQA1_53_32717215_exon2,AA_DQA1_54_32717218_exon2,AA_DQA1_55_32717221_exon2,AA_DQA1_56_32717224_exon2,AA_DQA1_61_32717239_exon2,AA_DQA1_64_32717248_exon2,AA_DQA1_66_32717254_exon2,AA_DQA1_69_32717263_exon2,AA_DQA1_75_32717281_exon2,AA_DQA1_76_32717284_exon2,AA_DQA1_80_32717296_exon2,AA_DQA1_107_32717790_exon3,AA_DQA1_129_32717856_exon3,AA_DQA1_130_32717859_exon3,AA_DQA1_139_32717886_exon3,AA_DQA1_156_32717937_exon3,AA_DQA1_160_32717949_exon3,AA_DQA1_161_32717952_exon3,AA_DQA1_163_32717958_exon3,AA_DQA1_175_32717994_exon3,AA_DQA1_187_32718388_exon4,AA_DQA1_199_32718424_exon4,AA_DQA1_207_32718448_exon4,AA_DQA1_215_32718472_exon4,AA_DQA1_218_32718481_exon4,AA_DQB1_234_32735627_exon6,AA_DQB1_233_32736241_exon5,AA_DQB1_232_32736244_exon5,AA_DQB1_231_32736247_exon5,AA_DQB1_230_32736250_exon5,AA_DQB1_229_32736253_exon5,AA_DQB1_228_32736256_exon5,AA_DQB1_227_32736259_exon5,AA_DQB1_224_32736753_exon4,AA_DQB1_221_32736762_exon4,AA_DQB1_220_32736765_exon4,AA_DQB1_203_32736816_exon4,AA_DQB1_197_32736834_exon4,AA_DQB1_185_32737386_exon3,AA_DQB1_182_32737395_exon3,AA_DQB1_167_32737440_exon3,AA_DQB1_140_32737521_exon3,AA_DQB1_135_32737536_exon3,AA_DQB1_130_32737551_exon3,AA_DQB1_126_32737563_exon3,AA_DQB1_125_32737566_exon3,AA_DQB1_116_32737593_exon3,AA_DQB1_90_32740560_exon2,AA_DQB1_89_32740563_exon2,AA_DQB1_87_32740569_exon2,AA_DQB1_86_32740572_exon2,AA_DQB1_85_32740575_exon2,AA_DQB1_84_32740578_exon2,AA_DQB1_77_32740599_exon2,AA_DQB1_75_32740605_exon2,AA_DQB1_74_32740608_exon2,AA_DQB1_71_32740617_exon2,AA_DQB1_70_32740620_exon2,AA_DQB1_67_32740629_exon2,AA_DQB1_66_32740632_exon2,AA_DQB1_57_32740659_exon2,AA_DQB1_56_32740662_exon2,AA_DQB1_55_32740665_exon2,AA_DQB1_53_32740671_exon2,AA_DQB1_52_32740674_exon2,AA_DQB1_47_32740689_exon2,AA_DQB1_46_32740692_exon2,AA_DQB1_45_32740695_exon2,AA_DQB1_38_32740716_exon2,AA_DQB1_37_32740719_exon2,AA_DQB1_30_32740740_exon2,AA_DQB1_28_32740746_exon2,AA_DQB1_26_32740752_exon2,AA_DQB1_23_32740761_exon2,AA_DQB1_14_32740788_exon2,AA_DQB1_13_32740791_exon2,AA_DQB1_9_32740803_exon2,AA_DQB1_3_32742259_exon1,AA_DPA1_228_33144412_exon4,AA_DPA1_160_33144830_exon3,AA_DPA1_127_33144929_exon3,AA_DPA1_111_33144977_exon3,AA_DPA1_83_33145401_exon2,AA_DPA1_50_33145500_exon2,AA_DPA1_31_33145557_exon2,AA_DPA1_11_33145617_exon2,AA_DPB1_8_33156441_exon2,AA_DPB1_9_33156444_exon2,AA_DPB1_11_33156450_exon2,AA_DPB1_35_33156522_exon2,AA_DPB1_36_33156525_exon2,AA_DPB1_55_33156582_exon2,AA_DPB1_56_33156585_exon2,AA_DPB1_57_33156588_exon2,AA_DPB1_65_33156612_exon2,AA_DPB1_69_33156624_exon2,AA_DPB1_76_33156645_exon2,AA_DPB1_84_33156669_exon2,AA_DPB1_85_33156672_exon2,AA_DPB1_86_33156675_exon2,AA_DPB1_87_33156678_exon2,AA_DPB1_96_33160656_exon3,AA_DPB1_170_33160878_exon3,AA_DPB1_178_33160902_exon3,AA_DPB1_205_33161530_exon4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0              plink_multialleic\n",
       "1              plink_multialleic\n",
       "2              plink_multialleic\n",
       "3              plink_multialleic\n",
       "4              plink_multialleic\n",
       "                 ...            \n",
       "546    phased_multialleic_always\n",
       "547    phased_multialleic_always\n",
       "548    phased_multialleic_always\n",
       "549    phased_multialleic_always\n",
       "550    phased_multialleic_always\n",
       "Name: from, Length: 821, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.info(\"plink, multialleic: {}\".format(','.join(plink_multialleic_df['name'].unique())))\n",
    "log.info(\"plink, multialleic always: {}\".format(','.join(plink_multialleic_always_df['name'].unique())))\n",
    "log.info(\"phased, multialleic: {}\".format(','.join(phased_multialleic_df['name'].unique())))\n",
    "log.info(\"phased, multialleic always: {}\".format(','.join(phased_multialleic_always_df['name'].unique())))\n",
    "\n",
    "multialleic_df_concat['from']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parse optional input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9 covariates loaded from data/out_assoc/ALP/step_01.covar\n"
     ]
    }
   ],
   "source": [
    "if args.covar is None:\n",
    "    covar=fam.iloc[:,:2]\n",
    "else:\n",
    "    covar=pd.read_csv(args.covar,sep='\\t')\n",
    "    covar.columns=['FID','IID']+covar.columns[2:].tolist()\n",
    "    covar=covar.astype({'FID':str,'IID':str})\n",
    "    \n",
    "    covar.iloc[:,2:]=covar.iloc[:,2:].astype(float)\n",
    "    covar.iloc[:,2:]=covar.iloc[:,2:].replace(-9,np.nan)\n",
    "    \n",
    "    log.info(\"{} covariates loaded from {}\".format(len(covar.columns[2:]),args.covar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63 conditions loaded from --condition-list data/out_assoc/ALP/step_01.cond\n",
      "Removed bialleic condition(AA_A_9_30018537_exon2_F) with correponding multialleic condition(AA_A_9_30018537_exon2)\n",
      "Finally 62 conditions remains\n",
      "*********\n",
      " HLA_A, AA_A_9_30018537_exon2, AA_A_17_30018561_exon2, AA_A_44_30018642_exon2, AA_A_56_30018678_exon2, AA_A_62_30018696_exon2, AA_A_63_30018699_exon2, AA_A_65_30018705_exon2, AA_A_66_30018708_exon2, AA_A_67_30018711_exon2, AA_A_70_30018720_exon2, AA_A_73_30018729_exon2, AA_A_74_30018732_exon2, AA_A_76_30018738_exon2, AA_A_77_30018741_exon2, AA_A_79_30018747_exon2, AA_A_80_30018750_exon2, AA_A_81_30018753_exon2, AA_A_82_30018756_exon2, AA_A_83_30018759_exon2, AA_A_90_30018780_exon2, AA_A_95_30019036_exon3, AA_A_97_30019042_exon3, AA_A_99_30019048_exon3, AA_A_102_30019057_exon3, AA_A_105_30019066_exon3, AA_A_107_30019072_exon3, AA_A_109_30019078_exon3, AA_A_114_30019093_exon3, AA_A_116_30019099_exon3, AA_A_127_30019132_exon3, AA_A_142_30019177_exon3, AA_A_144_30019183_exon3, AA_A_145_30019186_exon3, AA_A_149_30019198_exon3, AA_A_150_30019201_exon3, AA_A_151_30019204_exon3, AA_A_152_30019207_exon3, AA_A_156_30019219_exon3, AA_A_158_30019225_exon3, AA_A_161_30019234_exon3, AA_A_163_30019240_exon3, AA_A_166_30019249_exon3, AA_A_167_30019252_exon3, AA_A_184_30019882_exon4, AA_A_193_30019909_exon4, AA_A_194_30019912_exon4, AA_A_207_30019951_exon4, AA_A_246_30020068_exon4, AA_A_253_30020089_exon4, AA_A_276_30020260_exon5, AA_A_282_30020278_exon5, AA_A_294_30020314_exon5, AA_A_297_30020323_exon5, AA_A_298_30020326_exon5, AA_A_299_30020329_exon5, AA_A_307_30020353_exon5, AA_A_311_30020365_exon5, AA_A_321_30020837_exon6, AA_A_334_30021018_exon7, SNPS_A_28_30018337_exon1, 6:28000361_T/C\n",
      "*********\n"
     ]
    }
   ],
   "source": [
    "if args.condition_list is None:\n",
    "    condition_list=[]\n",
    "else:\n",
    "    with open(args.condition_list,'r') as f:\n",
    "        condition_list=f.read().strip().split('\\n')\n",
    "        if condition_list[0]=='':\n",
    "            condition_list=[]\n",
    "            log.warning(\"Empty --condition-list {}\".format(args.condition_list))\n",
    "        else:\n",
    "            condition_list.append('AA_A_9_30018537_exon2_F')\n",
    "            log.info(\"{} conditions loaded from --condition-list {}\".format(len(condition_list),args.condition_list))\n",
    "            if len(np.unique(condition_list))!=len(condition_list):\n",
    "                condition_list=np.unique(condition_list).tolist()\n",
    "                log.info(\"After removing duplicated conditions, {} conditions remains\".format(len(condition_list)))\n",
    "            #log.info(', '.join(condition_list))\n",
    "            for condition1 in condition_list:\n",
    "                if condition1 not in multialleic_df_concat['name'].values:\n",
    "                    for condition2 in condition_list:\n",
    "                        #print(condition2,multialleic_df_concat[multialleic_df_concat['name']==condition2]['marker'].values)\n",
    "                        if condition1 in multialleic_df_concat[multialleic_df_concat['name']==condition2]['marker'].values:\n",
    "                            condition_list.remove(condition1)\n",
    "                            log.info(\"Removed bialleic condition({}) with correponding multialleic condition({})\".format(condition1,condition2))\n",
    "            log.info(\"Finally {} conditions remains\".format(len(condition_list)))\n",
    "            log.info('*********\\n '+', '.join(condition_list)+'\\n*********')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check idx integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***************************************Input integrity check***************************************\n",
      "Passed individual integrity check (Individuals from --bfile is the same as individuals from --bgl-phased)\n",
      "Passed individual integrity check (Individuals from --bfile or --bgl-phased is the same as individuals from --covar)\n",
      "Passed condition integrity check (All variants in --condition-list are identified from loaded variants)\n"
     ]
    }
   ],
   "source": [
    "log.info_head(\"Input integrity check\")\n",
    "if plink_fam is not None and phased_FID_list is not None:\n",
    "    assert np.all(plink_fam['FID']==phased_FID_list)\n",
    "    assert np.all(plink_fam['IID']==phased_IID_list)\n",
    "    assert np.all(plink_fam['fID']==phased_fID_list)\n",
    "    assert np.all(plink_fam['mID']==phased_mID_list)\n",
    "    assert np.all(plink_fam['sex']==phased_sex_list)\n",
    "    log.info(\"Passed individual integrity check (Individuals from --bfile is the same as individuals from --bgl-phased)\")\n",
    "\n",
    "assert np.all(covar['FID']==(plink_fam['FID'] if plink_fam is not None else phased_FID_list))\n",
    "assert np.all(covar['IID']==(plink_fam['IID'] if plink_fam is not None else phased_IID_list))\n",
    "log.info(\"Passed individual integrity check (Individuals from --bfile or --bgl-phased is the same as individuals from --covar)\")\n",
    "\n",
    "diff=set(condition_list)\n",
    "if phased_marker_name_list is not None:\n",
    "    diff=diff.difference(phased_marker_name_list)\n",
    "if plink_bim is not None:\n",
    "    diff=diff.difference(plink_bim.index)\n",
    "diff=diff.difference(multialleic_df_concat['name'])\n",
    "assert len(diff)==0\n",
    "log.info(\"Passed condition integrity check (All variants in --condition-list are identified from loaded variants)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "**********************************Converting condtion to covariate**********************************\n"
     ]
    }
   ],
   "source": [
    "log.info_head(\"Converting condtion to covariate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def marker_data_to_onehot(aa_marker_data):\n",
    "    \n",
    "    aa_marker_data_unique=np.unique(aa_marker_data)\n",
    "    aa_marker_data_unique_nonan=aa_marker_data_unique[aa_marker_data_unique!='nan'].tolist()\n",
    "    aa_marker_data_unique_nan=aa_marker_data_unique_nonan+['nan']\n",
    "    \n",
    "    aa_marker_data_int_nan=list(map(lambda x: aa_marker_data_unique_nan.index(x),aa_marker_data))\n",
    "    \n",
    "    aa_marker_data_onehot_nan=np.zeros((len(aa_marker_data),len(aa_marker_data_unique_nan)))\n",
    "    aa_marker_data_onehot_nan[np.arange(len(aa_marker_data)),aa_marker_data_int_nan]=1\n",
    "    aa_marker_data_onehot_nonan=aa_marker_data_onehot_nan[:,:-1]\n",
    "    \n",
    "    return aa_marker_data_unique_nonan,aa_marker_data_onehot_nonan\n",
    "\n",
    "def prepare_onehot(aa_marker_data_unique_nonan,aa_marker_data_onehot_nonan,set_nan=True,cut_mostfrequent=True):\n",
    "    assert len(aa_marker_data_unique_nonan)==aa_marker_data_onehot_nonan.shape[1]\n",
    "    assert np.isnan(aa_marker_data_onehot_nonan).sum()==0\n",
    "    assert (np.nan not in aa_marker_data_unique_nonan) and ('nan' not in aa_marker_data_unique_nonan)\n",
    "    \n",
    "    aa_marker_data_onehot_nonan_sumrow=np.sum(aa_marker_data_onehot_nonan,axis=1)\n",
    "    aa_marker_data_onehot_nonan_sumcol=np.sum(aa_marker_data_onehot_nonan,axis=0)\n",
    "    #print(aa_marker_data_onehot_nonan_sumcol,np.argmax(aa_marker_data_onehot_nonan_sumcol))\n",
    "    #print(aa_marker_data_onehot_nonan_sumrow.shape,aa_marker_data_onehot_nonan_sumcol.shape)\n",
    "    #print(np.argmax(aa_marker_data_onehot_nonan_sumcol))\n",
    "    if set_nan:\n",
    "        aa_marker_data_onehot_nonan[aa_marker_data_onehot_nonan_sumrow!=1,:]=np.nan\n",
    "    if cut_mostfrequent:\n",
    "        aa_marker_data_unique_nonan=np.delete(aa_marker_data_unique_nonan, np.argmax(aa_marker_data_onehot_nonan_sumcol))\n",
    "        aa_marker_data_onehot_nonan=np.delete(aa_marker_data_onehot_nonan, np.argmax(aa_marker_data_onehot_nonan_sumcol), axis=1)\n",
    "    return aa_marker_data_unique_nonan,aa_marker_data_onehot_nonan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plink_get_dosage(marker,keep_allele_order=True,repeat=1):\n",
    "    dosage=plink.get_geno_marker(marker).astype(float)\n",
    "    dosage[dosage==-1]=np.nan\n",
    "    if keep_allele_order or ((dosage==0).sum()>(dosage==2).sum()):\n",
    "        a1=plink_bim.loc[marker]['a1']\n",
    "    else:\n",
    "        a1=plink_bim.loc[marker]['a2']\n",
    "        dosage=2-dosage\n",
    "    return a1,np.repeat(dosage,repeat)\n",
    "\n",
    "def phased_get_dosage(marker,a1=None):\n",
    "    phased_marker_idx=phased_marker_name_list.index(marker)\n",
    "    phased_marker_data=phased_marker_data_list[phased_marker_idx]\n",
    "    phased_marker_data_unique=np.unique(phased_marker_data)\n",
    "    if len(phased_marker_data_unique)>2:\n",
    "        raise NotImplementedError\n",
    "    if a1 is not None:\n",
    "        if a1==phased_marker_data_unique[1]:\n",
    "            a2=phased_marker_data_unique[0]     \n",
    "        elif a1==phased_marker_data_unique[0]:\n",
    "            a2=phased_marker_data_unique[1]       \n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    elif (phased_marker_data==phased_marker_data_unique[0]).sum()>(phased_marker_data==phased_marker_data_unique[1]).sum():\n",
    "        a1=phased_marker_data_unique[1]\n",
    "        a2=phased_marker_data_unique[0]\n",
    "    else:\n",
    "        a1=phased_marker_data_unique[0]\n",
    "        a2=phased_marker_data_unique[1]\n",
    "    phased_marker_data=np.where(phased_marker_data==a1, 1, phased_marker_data)\n",
    "    phased_marker_data=np.where(phased_marker_data==a2, 0, phased_marker_data)\n",
    "    return a1, phased_marker_data.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_phased=covar.loc[covar.index.repeat(2)].reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 bialleic markers from mulitalleic marker(HLA_A) were added.\n",
      "==> To avoid coliearity, HLA_A*24:02 removed from HLA_A*01:01, HLA_A*02:01, HLA_A*02:03, HLA_A*02:06, HLA_A*02:07, HLA_A*03:01, HLA_A*11:01, HLA_A*24:02, HLA_A*26:01, HLA_A*26:02, HLA_A*26:03, HLA_A*29:01, HLA_A*30:01, HLA_A*30:04, HLA_A*31:01, HLA_A*32:01, HLA_A*33:03\n",
      "3 bialleic markers from mulitalleic marker(AA_A_9_30018537_exon2) were added.\n",
      "==> To avoid coliearity, AA_A_9_30018537_exon2_S removed from AA_A_9_30018537_exon2_F, AA_A_9_30018537_exon2_S, AA_A_9_30018537_exon2_T, AA_A_9_30018537_exon2_Y\n",
      "1 bialleic markers from mulitalleic marker(AA_A_17_30018561_exon2) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_44_30018642_exon2) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_56_30018678_exon2) were added.\n",
      "4 bialleic markers from mulitalleic marker(AA_A_62_30018696_exon2) were added.\n",
      "==> To avoid coliearity, AA_A_62_30018696_exon2_G removed from AA_A_62_30018696_exon2_E, AA_A_62_30018696_exon2_G, AA_A_62_30018696_exon2_L, AA_A_62_30018696_exon2_Q, AA_A_62_30018696_exon2_R\n",
      "2 bialleic markers from mulitalleic marker(AA_A_63_30018699_exon2) were added.\n",
      "==> To avoid coliearity, AA_A_63_30018699_exon2_E removed from AA_A_63_30018699_exon2_E, AA_A_63_30018699_exon2_N, AA_A_63_30018699_exon2_Q\n",
      "1 bialleic markers from mulitalleic marker(AA_A_65_30018705_exon2) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_66_30018708_exon2) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_67_30018711_exon2) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_70_30018720_exon2) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_73_30018729_exon2) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_74_30018732_exon2) were added.\n",
      "2 bialleic markers from mulitalleic marker(AA_A_76_30018738_exon2) were added.\n",
      "==> To avoid coliearity, AA_A_76_30018738_exon2_V removed from AA_A_76_30018738_exon2_A, AA_A_76_30018738_exon2_E, AA_A_76_30018738_exon2_V\n",
      "2 bialleic markers from mulitalleic marker(AA_A_77_30018741_exon2) were added.\n",
      "==> To avoid coliearity, AA_A_77_30018741_exon2_D removed from AA_A_77_30018741_exon2_D, AA_A_77_30018741_exon2_N, AA_A_77_30018741_exon2_S\n",
      "1 bialleic markers from mulitalleic marker(AA_A_79_30018747_exon2) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_80_30018750_exon2) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_81_30018753_exon2) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_82_30018756_exon2) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_83_30018759_exon2) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_90_30018780_exon2) were added.\n",
      "2 bialleic markers from mulitalleic marker(AA_A_95_30019036_exon3) were added.\n",
      "==> To avoid coliearity, AA_A_95_30019036_exon3_I removed from AA_A_95_30019036_exon3_I, AA_A_95_30019036_exon3_L, AA_A_95_30019036_exon3_V\n",
      "2 bialleic markers from mulitalleic marker(AA_A_97_30019042_exon3) were added.\n",
      "==> To avoid coliearity, AA_A_97_30019042_exon3_M removed from AA_A_97_30019042_exon3_I, AA_A_97_30019042_exon3_M, AA_A_97_30019042_exon3_R\n",
      "2 bialleic markers from mulitalleic marker(AA_A_99_30019048_exon3) were added.\n",
      "==> To avoid coliearity, AA_A_99_30019048_exon3_Y removed from AA_A_99_30019048_exon3_C, AA_A_99_30019048_exon3_F, AA_A_99_30019048_exon3_Y\n",
      "1 bialleic markers from mulitalleic marker(AA_A_102_30019057_exon3) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_105_30019066_exon3) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_107_30019072_exon3) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_109_30019078_exon3) were added.\n",
      "3 bialleic markers from mulitalleic marker(AA_A_114_30019093_exon3) were added.\n",
      "==> To avoid coliearity, AA_A_114_30019093_exon3_H removed from AA_A_114_30019093_exon3_E, AA_A_114_30019093_exon3_H, AA_A_114_30019093_exon3_Q, AA_A_114_30019093_exon3_R\n",
      "3 bialleic markers from mulitalleic marker(AA_A_116_30019099_exon3) were added.\n",
      "==> To avoid coliearity, AA_A_116_30019099_exon3_Y removed from AA_A_116_30019099_exon3_D, AA_A_116_30019099_exon3_H, AA_A_116_30019099_exon3_N, AA_A_116_30019099_exon3_Y\n",
      "1 bialleic markers from mulitalleic marker(AA_A_127_30019132_exon3) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_142_30019177_exon3) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_144_30019183_exon3) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_145_30019186_exon3) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_149_30019198_exon3) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_150_30019201_exon3) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_151_30019204_exon3) were added.\n",
      "3 bialleic markers from mulitalleic marker(AA_A_152_30019207_exon3) were added.\n",
      "==> To avoid coliearity, AA_A_152_30019207_exon3_V removed from AA_A_152_30019207_exon3_A, AA_A_152_30019207_exon3_E, AA_A_152_30019207_exon3_V, AA_A_152_30019207_exon3_W\n",
      "3 bialleic markers from mulitalleic marker(AA_A_156_30019219_exon3) were added.\n",
      "==> To avoid coliearity, AA_A_156_30019219_exon3_L removed from AA_A_156_30019219_exon3_L, AA_A_156_30019219_exon3_Q, AA_A_156_30019219_exon3_R, AA_A_156_30019219_exon3_W\n",
      "1 bialleic markers from mulitalleic marker(AA_A_158_30019225_exon3) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_161_30019234_exon3) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_163_30019240_exon3) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_166_30019249_exon3) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_167_30019252_exon3) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_184_30019882_exon4) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_193_30019909_exon4) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_194_30019912_exon4) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_207_30019951_exon4) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_246_30020068_exon4) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_253_30020089_exon4) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_276_30020260_exon5) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_282_30020278_exon5) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_294_30020314_exon5) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_297_30020323_exon5) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_298_30020326_exon5) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_299_30020329_exon5) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_307_30020353_exon5) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_311_30020365_exon5) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_321_30020837_exon6) were added.\n",
      "1 bialleic markers from mulitalleic marker(AA_A_334_30021018_exon7) were added.\n",
      "1 bialleic marker SNPS_A_28_30018337_exon1 was added from --bgl-phased\n",
      "1 bialleic marker 6:28000361_T/C was added from --bfile\n"
     ]
    }
   ],
   "source": [
    "for condition in condition_list:\n",
    "    if condition in multialleic_df_concat['name'].values:\n",
    "        if condition in phased_multialleic_df['name'].values:\n",
    "            bialleic_marker_list=np.array(phased_multialleic_df['marker'][phased_multialleic_df['name']==condition].values)\n",
    "            bialleic_marker_info_list=[phased_get_dosage(bialleic_marker) for bialleic_marker in bialleic_marker_list]\n",
    "        elif condition in phased_multialleic_always_df['name'].values:\n",
    "            bialleic_marker_list=np.array(phased_multialleic_always_df['marker'][phased_multialleic_always_df['name']==condition].values)\n",
    "            bialleic_marker_info_list=[phased_get_dosage(bialleic_marker) for bialleic_marker in bialleic_marker_list]        \n",
    "            \n",
    "        elif condition in plink_multialleic_df['name'].values:   \n",
    "            bialleic_marker_list=np.array(plink_multialleic_df['marker'][plink_multialleic_df['name']==condition].values)\n",
    "            bialleic_marker_info_list=[plink_get_dosage(bialleic_marker,repeat=2) for bialleic_marker in bialleic_marker_list]   \n",
    "        elif condition in plink_multialleic_always_df['name'].values:   \n",
    "            bialleic_marker_list=np.array(plink_multialleic_always_df['marker'][plink_multialleic_always_df['name']==condition].values)\n",
    "            bialleic_marker_info_list=[plink_get_dosage(bialleic_marker,repeat=2) for bialleic_marker in bialleic_marker_list]               \n",
    "        if len(np.unique(bialleic_marker_list))!=len(bialleic_marker_list):\n",
    "            raise        \n",
    "        bialleic_marker_allele=[allele for allele,dosage in bialleic_marker_info_list]\n",
    "        bialleic_marker_dosage=np.array([dosage for allele,dosage in bialleic_marker_info_list]).transpose()\n",
    "        bialleic_marker_dosage_sumcol=bialleic_marker_dosage.sum(axis=1)\n",
    "        bialleic_marker_dosage_sumrow=bialleic_marker_dosage.sum(axis=0)\n",
    "        \n",
    "        if bialleic_marker_dosage_sumrow.shape[0]>1:\n",
    "            bialleic_marker_list_cut=np.delete(bialleic_marker_list, np.argmax(bialleic_marker_dosage_sumrow))\n",
    "            bialleic_marker_dosage_cut=np.delete(bialleic_marker_dosage, np.argmax(bialleic_marker_dosage_sumrow),axis=1)\n",
    "        else:\n",
    "            bialleic_marker_list_cut=bialleic_marker_list\n",
    "            bialleic_marker_dosage_cut=bialleic_marker_dosage\n",
    "            \n",
    "        for bialleic_marker_idx,bialleic_marker in enumerate(bialleic_marker_list_cut):\n",
    "            covar_phased[bialleic_marker]=bialleic_marker_dosage_cut[:,bialleic_marker_idx]\n",
    "            \n",
    "        log.info(\"{} bialleic markers from mulitalleic marker({}) were added.\".format(len(bialleic_marker_list_cut),condition))\n",
    "        \n",
    "        if bialleic_marker_dosage_sumrow.shape[0]>1:\n",
    "            log.info(\"==> To avoid coliearity, {} removed from {}\".format(bialleic_marker_list[np.argmax(bialleic_marker_dosage_sumrow)] ,', '.join(bialleic_marker_list)))\n",
    "    elif phased_marker_name_list is not None and condition in phased_marker_name_list:\n",
    "        allele,dosage=phased_get_dosage(condition)\n",
    "        covar_phased[condition]=dosage\n",
    "        log.info(\"1 bialleic marker {} was added from --bgl-phased\".format(condition))\n",
    "    elif plink_bim is not None and condition in plink_bim.index:\n",
    "        allele,dosage=plink_get_dosage(condition,repeat=2)\n",
    "        covar_phased[condition]=dosage        \n",
    "        log.info(\"1 bialleic marker {} was added from --bfile\".format(condition))\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_marker_list=np.unique(plink_bim.index.tolist()+phased_marker_name_list+multialleic_df_concat['name'].unique().tolist()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_marker_list=pd.Index(test_marker_list)\n",
    "test_marker_list=test_marker_list.difference(multialleic_df_concat_always['marker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plink is not None:\n",
    "    \n",
    "    plink_bialleic_list=plink_bim.index\n",
    "    plink_bialleic_list=plink_bialleic_list.difference(plink_multialleic_dict.keys())\n",
    "    plink_bialleic_list=plink_bialleic_list.difference(plink_multialleic_always_dict.keys())    \n",
    "    \n",
    "    for marker_idx,marker in enumerate(plink_bialleic_list):\n",
    "        if marker_idx%10==0:\n",
    "            sys.stdout.write('\\r{:.2f}%'.format(100*marker_idx/len(plink_bialleic_list)))\n",
    "            sys.stdout.flush()           \n",
    "\n",
    "        \n",
    "        dosage=plink.get_geno_marker(marker).astype(float)\n",
    "        dosage[dosage==-1]=np.nan\n",
    "                \n",
    "        x_data_intercept=np.array([np.ones(plink_fam.shape[0])]).transpose()    \n",
    "        x_data_dosage=plink.get_geno_marker(marker).astype(float);x_data_dosage[x_data_dosage==-1]=np.nan\n",
    "        x_data_dosage=np.expand_dims(x_data_dosage,axis=1)\n",
    "        x_data_covariate=covar.iloc[:,2:].values\n",
    "\n",
    "        x_data=np.concatenate([x_data_intercept,x_data_covariate,x_data_dosage],axis=1)#[~x_y_data_nan]\n",
    "        x_data_names=np.array(['const']+covar.iloc[:,2:].columns.values.tolist()+['THIS'])\n",
    "        #x_data_null=np.concatenate([x_data_intercept,x_data_covariate],axis=1)#[~x_y_data_nan]\n",
    "        y_data=pheno['pheno']\n",
    "        \n",
    "        family=(sm.families.Gaussian() if assoc=='linear' else sm.families.Binomial())\n",
    "        model=sm.GLM(y_data,x_data, family=family,missing='drop')\n",
    "        #model_null=sm.GLM(y_data,x_data_null, family=family,missing='drop')\n",
    "        model_result=model.fit()\n",
    "        \n",
    "        \n",
    "        for model_result_idx in range(len(model_result.params)):\n",
    "            \n",
    "            assoc_result_record(marker_name=marker,\n",
    "                                P=model_result.pvalues.iloc[model_result_idx],\n",
    "                                coef=model_result.params.iloc[model_result_idx],\n",
    "                                std=model_result.bse.iloc[model_result_idx],\n",
    "                                Z=model_result.tvalues.iloc[model_result_idx],\n",
    "                                term=x_data_names[model_result_idx],\n",
    "                                nobs=model_result.nobs,\n",
    "                                note='plink bialleic'\n",
    "                               \n",
    "                               )\n",
    "        #model_result_null=model_null.fit()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    assert len(aa_marker_data_unique_nonan)==aa_marker_data_onehot_nonan.shape[1]\n",
    "    assert np.isnan(aa_marker_data_onehot_nonan).sum()==0\n",
    "    assert (np.nan not in aa_marker_data_unique_nonan) and ('nan' not in aa_marker_data_unique_nonan)\n",
    "    \n",
    "    aa_marker_data_onehot_nonan_sumrow=np.sum(aa_marker_data_onehot_nonan,axis=1)\n",
    "    aa_marker_data_onehot_nonan_sumcol=np.sum(aa_marker_data_onehot_nonan,axis=0)\n",
    "    #print(aa_marker_data_onehot_nonan_sumcol,np.argmax(aa_marker_data_onehot_nonan_sumcol))\n",
    "    #print(aa_marker_data_onehot_nonan_sumrow.shape,aa_marker_data_onehot_nonan_sumcol.shape)\n",
    "    #print(np.argmax(aa_marker_data_onehot_nonan_sumcol))\n",
    "    if set_nan:\n",
    "        aa_marker_data_onehot_nonan[aa_marker_data_onehot_nonan_sumrow!=1,:]=np.nan\n",
    "    if cut_mostfrequent:\n",
    "        aa_marker_data_unique_nonan=np.delete(aa_marker_data_unique_nonan, np.argmax(aa_marker_data_onehot_nonan_sumcol))\n",
    "        aa_marker_data_onehot_nonan=np.delete(aa_marker_data_onehot_nonan, np.argmax(aa_marker_data_onehot_nonan_sumcol), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for marker in plink_bialleic_list:\n",
    "    name,allele=(re_exp.search(marker).group('name'),re_exp.search(marker).group('allele')) if re_exp.search(marker) is not None else (None,None)\n",
    "    if name is not None and name.split('*')[0].split('_')[1]==HLA_gene:\n",
    "        marker_dosage_list=marker_dosage_list_dict.get(name,[])\n",
    "        marker_dosage_list.append({\"marker\":marker,\"dosage\":plink_KCHIP_HLA_AA_SNP_1000G.get_geno_marker(marker)})\n",
    "        marker_dosage_list_dict[name]=marker_dosage_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phased_get_dosage('rs9380355','A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "assoc_result_list=[]\n",
    "\n",
    "def assoc_result_record(marker_name='',P=np.nan,nobs=np.nan,coef=np.nan,std=np.nan,Z=np.nan,chisq=np.nan,df=np.nan,term=np.nan,note=''):\n",
    "    assoc_result_list.append({'marker_name':marker_name,'P':P,'nobs':nobs,'coef':coef,'std':std,'Z':Z,'chisq':chisq,'df':df,'term':term,'note':note})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.94%"
     ]
    }
   ],
   "source": [
    "if plink is not None:\n",
    "    \n",
    "    plink_bialleic_list=plink_bim.index\n",
    "    plink_bialleic_list=plink_bialleic_list.difference(plink_multialleic_dict.keys())\n",
    "    plink_bialleic_list=plink_bialleic_list.difference(plink_multialleic_always_dict.keys())    \n",
    "    \n",
    "    for marker_idx,marker in enumerate(plink_bialleic_list):\n",
    "        if marker_idx%10==0:\n",
    "            sys.stdout.write('\\r{:.2f}%'.format(100*marker_idx/len(plink_bialleic_list)))\n",
    "            sys.stdout.flush()           \n",
    "\n",
    "        \n",
    "        dosage=plink.get_geno_marker(marker).astype(float)\n",
    "        dosage[dosage==-1]=np.nan\n",
    "                \n",
    "        x_data_intercept=np.array([np.ones(plink_fam.shape[0])]).transpose()    \n",
    "        x_data_dosage=plink.get_geno_marker(marker).astype(float);x_data_dosage[x_data_dosage==-1]=np.nan\n",
    "        x_data_dosage=np.expand_dims(x_data_dosage,axis=1)\n",
    "        x_data_covariate=covar.iloc[:,2:].values\n",
    "\n",
    "        x_data=np.concatenate([x_data_intercept,x_data_covariate,x_data_dosage],axis=1)#[~x_y_data_nan]\n",
    "        x_data_names=np.array(['const']+covar.iloc[:,2:].columns.values.tolist()+['THIS'])\n",
    "        #x_data_null=np.concatenate([x_data_intercept,x_data_covariate],axis=1)#[~x_y_data_nan]\n",
    "        y_data=pheno['pheno']\n",
    "        \n",
    "        family=(sm.families.Gaussian() if assoc=='linear' else sm.families.Binomial())\n",
    "        model=sm.GLM(y_data,x_data, family=family,missing='drop')\n",
    "        #model_null=sm.GLM(y_data,x_data_null, family=family,missing='drop')\n",
    "        model_result=model.fit()\n",
    "        \n",
    "        \n",
    "        for model_result_idx in range(len(model_result.params)):\n",
    "            \n",
    "            assoc_result_record(marker_name=marker,\n",
    "                                P=model_result.pvalues.iloc[model_result_idx],\n",
    "                                coef=model_result.params.iloc[model_result_idx],\n",
    "                                std=model_result.bse.iloc[model_result_idx],\n",
    "                                Z=model_result.tvalues.iloc[model_result_idx],\n",
    "                                term=x_data_names[model_result_idx],\n",
    "                                nobs=model_result.nobs,\n",
    "                                note='plink bialleic'\n",
    "                               \n",
    "                               )\n",
    "        #model_result_null=model_null.fit()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marker_name</th>\n",
       "      <th>P</th>\n",
       "      <th>nobs</th>\n",
       "      <th>coef</th>\n",
       "      <th>std</th>\n",
       "      <th>Z</th>\n",
       "      <th>chisq</th>\n",
       "      <th>df</th>\n",
       "      <th>term</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INS_SNPS_A_1255x1256_30019564</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>59468</td>\n",
       "      <td>1.089192e+02</td>\n",
       "      <td>2.063120e+00</td>\n",
       "      <td>52.793434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>const</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INS_SNPS_A_1255x1256_30019564</td>\n",
       "      <td>4.719384e-01</td>\n",
       "      <td>59468</td>\n",
       "      <td>1.307830e+01</td>\n",
       "      <td>1.818126e+01</td>\n",
       "      <td>0.719329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INS_SNPS_A_1255x1256_30019564</td>\n",
       "      <td>9.162841e-04</td>\n",
       "      <td>59468</td>\n",
       "      <td>-6.190119e+01</td>\n",
       "      <td>1.867281e+01</td>\n",
       "      <td>-3.315045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INS_SNPS_A_1255x1256_30019564</td>\n",
       "      <td>7.809197e-01</td>\n",
       "      <td>59468</td>\n",
       "      <td>5.342343e+00</td>\n",
       "      <td>1.920872e+01</td>\n",
       "      <td>0.278121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INS_SNPS_A_1255x1256_30019564</td>\n",
       "      <td>3.753067e-01</td>\n",
       "      <td>59468</td>\n",
       "      <td>1.713986e+01</td>\n",
       "      <td>1.933263e+01</td>\n",
       "      <td>0.886577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>INS_SNPS_C_573x574_31347254</td>\n",
       "      <td>1.172849e-32</td>\n",
       "      <td>59467</td>\n",
       "      <td>-7.431318e+00</td>\n",
       "      <td>6.244411e-01</td>\n",
       "      <td>-11.900752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sex</td>\n",
       "      <td>plink bialleic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>INS_SNPS_C_573x574_31347254</td>\n",
       "      <td>8.602908e-01</td>\n",
       "      <td>59467</td>\n",
       "      <td>1.584112e-14</td>\n",
       "      <td>9.000431e-14</td>\n",
       "      <td>0.176004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AS</td>\n",
       "      <td>plink bialleic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>INS_SNPS_C_573x574_31347254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59467</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NC</td>\n",
       "      <td>plink bialleic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>INS_SNPS_C_573x574_31347254</td>\n",
       "      <td>4.066620e-77</td>\n",
       "      <td>59467</td>\n",
       "      <td>-9.883373e+00</td>\n",
       "      <td>5.317253e-01</td>\n",
       "      <td>-18.587366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6:30165273_C/T</td>\n",
       "      <td>plink bialleic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>INS_SNPS_C_573x574_31347254</td>\n",
       "      <td>6.539578e-07</td>\n",
       "      <td>59467</td>\n",
       "      <td>3.206771e+00</td>\n",
       "      <td>6.446341e-01</td>\n",
       "      <td>4.974561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>THIS</td>\n",
       "      <td>plink bialleic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       marker_name             P   nobs          coef  \\\n",
       "0    INS_SNPS_A_1255x1256_30019564  0.000000e+00  59468  1.089192e+02   \n",
       "1    INS_SNPS_A_1255x1256_30019564  4.719384e-01  59468  1.307830e+01   \n",
       "2    INS_SNPS_A_1255x1256_30019564  9.162841e-04  59468 -6.190119e+01   \n",
       "3    INS_SNPS_A_1255x1256_30019564  7.809197e-01  59468  5.342343e+00   \n",
       "4    INS_SNPS_A_1255x1256_30019564  3.753067e-01  59468  1.713986e+01   \n",
       "..                             ...           ...    ...           ...   \n",
       "325    INS_SNPS_C_573x574_31347254  1.172849e-32  59467 -7.431318e+00   \n",
       "326    INS_SNPS_C_573x574_31347254  8.602908e-01  59467  1.584112e-14   \n",
       "327    INS_SNPS_C_573x574_31347254           NaN  59467  0.000000e+00   \n",
       "328    INS_SNPS_C_573x574_31347254  4.066620e-77  59467 -9.883373e+00   \n",
       "329    INS_SNPS_C_573x574_31347254  6.539578e-07  59467  3.206771e+00   \n",
       "\n",
       "              std          Z  chisq  df            term            note  \n",
       "0    2.063120e+00  52.793434    NaN NaN           const                  \n",
       "1    1.818126e+01   0.719329    NaN NaN             PC1                  \n",
       "2    1.867281e+01  -3.315045    NaN NaN             PC2                  \n",
       "3    1.920872e+01   0.278121    NaN NaN             PC3                  \n",
       "4    1.933263e+01   0.886577    NaN NaN             PC4                  \n",
       "..            ...        ...    ...  ..             ...             ...  \n",
       "325  6.244411e-01 -11.900752    NaN NaN             sex  plink bialleic  \n",
       "326  9.000431e-14   0.176004    NaN NaN              AS  plink bialleic  \n",
       "327  0.000000e+00        NaN    NaN NaN              NC  plink bialleic  \n",
       "328  5.317253e-01 -18.587366    NaN NaN  6:30165273_C/T  plink bialleic  \n",
       "329  6.446341e-01   4.974561    NaN NaN            THIS  plink bialleic  \n",
       "\n",
       "[330 rows x 10 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(assoc_result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59467,\n",
       " 3.206771299364718,\n",
       " 0.6446340696295587,\n",
       " 4.9745606855801165,\n",
       " 6.539577578993869e-07)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result.nobs,model_result.params.iloc[-1],model_result.bse.iloc[-1],model_result.tvalues.iloc[-1],model_result.pvalues.iloc[-1]#.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((125673, 11), 11)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape,len(x_data_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rs7755402', 'rs9468471', 'rs9468473', 'rs7743837', 'rs6924824',\n",
       "       'rs6456886', 'rs6456889', 'rs7341218', 'rs2143574', 'rs9348819',\n",
       "       ...\n",
       "       'rs2747477', 'rs456993', 'rs465506', 'rs465474', 'rs461964', 'rs211456',\n",
       "       'rs453590', 'rs10807124', 'rs2247385', 'rs9380355'],\n",
       "      dtype='object', name='snp', length=10952)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for marker in plink_bialleic_list:\n",
    "    plink\n",
    "    #name,allele=(re_exp.search(marker).group('name'),re_exp.search(marker).group('allele')) if re_exp.search(marker) is not None else (None,None)\n",
    "    #if name is not None and name.split('*')[0].split('_')[1]==HLA_gene:\n",
    "    #    marker_dosage_list=marker_dosage_list_dict.get(name,[])\n",
    "    #    marker_dosage_list.append({\"marker\":marker,\"dosage\":plink_KCHIP_HLA_AA_SNP_1000G.get_geno_marker(marker)})\n",
    "    #    marker_dosage_list_dict[name]=marker_dosage_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['INS_SNPS_A_1255x1256_30019564', 'INS_SNPS_A_1406x1407_30019716',\n",
       "       'INS_SNPS_A_2070x2071_30020380', 'INS_SNPS_B_1159x1160_31431756',\n",
       "       'INS_SNPS_B_1890x1891_31431024', 'INS_SNPS_B_688x689_31432226',\n",
       "       'INS_SNPS_B_84x85_31432830', 'INS_SNPS_C_1910x1911_31345918',\n",
       "       'INS_SNPS_C_2264x2265_31345564', 'INS_SNPS_C_573x574_31347254',\n",
       "       ...\n",
       "       'rs970901', 'rs971570', 'rs9784758', 'rs9784876', 'rs983561',\n",
       "       'rs984778', 'rs986475', 'rs987870', 'rs991760', 'rs9986640'],\n",
       "      dtype='object', name='snp', length=10817)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plink_bialleic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_bim,(SNP,row) in enumerate(plink_bim.iterrows()):\n",
    "    y_data=pheno['pheno'].replace(-9,np.nan)\n",
    "    \n",
    "    \n",
    "    x_data_intercept=np.array([np.ones(plink_KCHIP_HLA_AA_SNP_1000G_fam.shape[0])]).transpose()    \n",
    "    x_data_dosage=plink_KCHIP_HLA_AA_SNP_1000G.get_geno_marker(SNP).astype(float);x_data_dosage[x_data_dosage==-1]=np.nan\n",
    "    x_data_dosage=np.expand_dims(x_data_dosage,axis=1)\n",
    "    x_data_covariate=covariate_plink_df.values\n",
    "    #print(x_data_intercept.shape,covariate_plink_df.values.shape)\n",
    "    x_data=np.concatenate([x_data_intercept,x_data_covariate,x_data_dosage],axis=1)#[~x_y_data_nan]\n",
    "    x_data_null=np.concatenate([x_data_intercept,x_data_covariate],axis=1)#[~x_y_data_nan]\n",
    "    \n",
    "    family=(sm.families.Gaussian() if phenotype_type=='continuous' else sm.families.Binomial())\n",
    "    model=sm.GLM(y_data,x_data, family=family,missing='drop')\n",
    "    model_null=sm.GLM(y_data,x_data_null, family=family,missing='drop')\n",
    "    model_result=model.fit()\n",
    "    model_result_null=model_null.fit()\n",
    "    \n",
    "    print(model_result.summary())\n",
    "    if idx_bim==2:\n",
    "        break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-------------------------------Checking missing values(observations)-------------------------------\n"
     ]
    }
   ],
   "source": [
    "log.info_head(\"Checking missing values(observations)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    conditional_omnibus_list=[]\n",
    "\n",
    "    for HLA_gene in conditional_variant_list_HLA_AA:\n",
    "        marker_dosage_list_dict={}\n",
    "        for re_exp in [HLA_re_exp,AA_re_exp]:\n",
    "            for marker in plink_KCHIP_HLA_AA_SNP_1000G_bim.index:\n",
    "                name,allele=(re_exp.search(marker).group('name'),re_exp.search(marker).group('allele')) if re_exp.search(marker) is not None else (None,None)\n",
    "                if name is not None and name.split('*')[0].split('_')[1]==HLA_gene:\n",
    "                    marker_dosage_list=marker_dosage_list_dict.get(name,[])\n",
    "                    marker_dosage_list.append({\"marker\":marker,\"dosage\":plink_KCHIP_HLA_AA_SNP_1000G.get_geno_marker(marker)})\n",
    "                    marker_dosage_list_dict[name]=marker_dosage_list\n",
    "\n",
    "        for key,marker_dosage_list in marker_dosage_list_dict.items():\n",
    "            marker_list=[marker_dosage['marker'] for marker_dosage in marker_dosage_list]\n",
    "            dosage_array=np.array([marker_dosage['dosage'] for marker_dosage in marker_dosage_list]).transpose()\n",
    "            if len(marker_list)>1:\n",
    "                marker_list_cut=np.delete(marker_list,dosage_array.sum(axis=0).argmax())\n",
    "                dosage_array_cut=np.delete(dosage_array,dosage_array.sum(axis=0).argmax(),axis=1)\n",
    "            else:\n",
    "                marker_list_cut=marker_list\n",
    "                dosage_array_cut=dosage_array\n",
    "\n",
    "            for i,marker in enumerate(marker_list_cut):\n",
    "                covariate_plink_df[marker]=dosage_array_cut[:,i]\n",
    "\n",
    "        conditional_omnibus_list+=marker_dosage_list_dict.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marker_data_to_onehot(aa_marker_data):\n",
    "    \n",
    "    aa_marker_data_unique=np.unique(aa_marker_data)\n",
    "    aa_marker_data_unique_nonan=aa_marker_data_unique[aa_marker_data_unique!='nan'].tolist()\n",
    "    aa_marker_data_unique_nan=aa_marker_data_unique_nonan+['nan']\n",
    "    \n",
    "    aa_marker_data_int_nan=list(map(lambda x: aa_marker_data_unique_nan.index(x),aa_marker_data))\n",
    "    \n",
    "    aa_marker_data_onehot_nan=np.zeros((len(aa_marker_data),len(aa_marker_data_unique_nan)))\n",
    "    aa_marker_data_onehot_nan[np.arange(len(aa_marker_data)),aa_marker_data_int_nan]=1\n",
    "    aa_marker_data_onehot_nonan=aa_marker_data_onehot_nan[:,:-1]\n",
    "    \n",
    "    return aa_marker_data_unique_nonan,aa_marker_data_onehot_nonan\n",
    "\n",
    "def prepare_onehot(aa_marker_data_unique_nonan,aa_marker_data_onehot_nonan,set_nan=True,cut_mostfrequent=True):\n",
    "    assert len(aa_marker_data_unique_nonan)==aa_marker_data_onehot_nonan.shape[1]\n",
    "    assert np.isnan(aa_marker_data_onehot_nonan).sum()==0\n",
    "    assert (np.nan not in aa_marker_data_unique_nonan) and ('nan' not in aa_marker_data_unique_nonan)\n",
    "    \n",
    "    aa_marker_data_onehot_nonan_sumrow=np.sum(aa_marker_data_onehot_nonan,axis=1)\n",
    "    aa_marker_data_onehot_nonan_sumcol=np.sum(aa_marker_data_onehot_nonan,axis=0)\n",
    "    #print(aa_marker_data_onehot_nonan_sumcol,np.argmax(aa_marker_data_onehot_nonan_sumcol))\n",
    "    #print(aa_marker_data_onehot_nonan_sumrow.shape,aa_marker_data_onehot_nonan_sumcol.shape)\n",
    "    #print(np.argmax(aa_marker_data_onehot_nonan_sumcol))\n",
    "    if set_nan:\n",
    "        aa_marker_data_onehot_nonan[aa_marker_data_onehot_nonan_sumrow!=1,:]=np.nan\n",
    "    if cut_mostfrequent:\n",
    "        aa_marker_data_unique_nonan=np.delete(aa_marker_data_unique_nonan, np.argmax(aa_marker_data_onehot_nonan_sumcol))\n",
    "        aa_marker_data_onehot_nonan=np.delete(aa_marker_data_onehot_nonan, np.argmax(aa_marker_data_onehot_nonan_sumcol), axis=1)\n",
    "    return aa_marker_data_unique_nonan,aa_marker_data_onehot_nonan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_pheno=np.repeat(pheno['pheno'].values,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_pheno_nan=np.isnan(y_data_pheno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.var(y_data_pheno[~y_data_pheno_nan])==0:\n",
    "    log.error(\"No variance in y_data\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "missing values in y_data_pheno: 138046\n"
     ]
    }
   ],
   "source": [
    "log.info(\"missing values in y_data_pheno: {}\".format(y_data_pheno_nan.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_intercept=np.array([np.ones(2*fam.shape[0])]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_covar=np.repeat(covar.iloc[:,2:].values,2,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "missing values in x_data_covar: 0\n"
     ]
    }
   ],
   "source": [
    "x_data_covar_nan=np.any(np.isnan(x_data_covar),axis=1)\n",
    "log.info(\"missing values in x_data_covar: {}\".format(x_data_covar_nan.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_covar_varcheck=np.array([np.var(covar) for covar in x_data_covar[~x_data_covar_nan].transpose()])==0\n",
    "\n",
    "if np.any(x_data_covar_varcheck):\n",
    "    log.info(\"Removed covariates of no variance\"+\", \".join(covar.columns[2:][x_data_covar_varcheck].tolist()))\n",
    "    x_data_covar=np.delete(x_data_covar,np.arange(len(x_data_covar_varcheck))[x_data_covar_varcheck],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (x_data_covar.size!=0) and (np.linalg.matrix_rank(x_data_covar)<x_data_covar.shape[1]):\n",
    "    log.info(\"duplicated covariates were found. (rank(covariates)< # of covarirates))\")\n",
    "    #raise\n",
    "    #x_data_covar=np.delete(x_data_covar,np.arange(len(x_data_covar_varcheck))[x_data_covar_varcheck],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list=[x_data_intercept[:,0:0]]\n",
    "for aa_marker_name in condition_list:\n",
    "    aa_marker_data=aa_marker_data_list[aa_marker_name_list.index(aa_marker_name)]\n",
    "\n",
    "    aa_marker_data_unique,aa_marker_data_onehot=marker_data_to_onehot(aa_marker_data)\n",
    "    aa_marker_data_unique_cut,aa_marker_data_onehot_cut=prepare_onehot(aa_marker_data_unique,aa_marker_data_onehot,set_nan=True,cut_mostfrequent=True)        \n",
    "    temp_list.append(aa_marker_data_onehot_cut)\n",
    "    \n",
    "x_data_condition=np.concatenate(temp_list,axis=1)\n",
    "x_data_condition_nan=np.any(np.isnan(x_data_condition),axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "missing values in x_data_condition: 97\n"
     ]
    }
   ],
   "source": [
    "log.info(\"missing values in x_data_condition: {}\".format(x_data_condition_nan.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx_data_condition=np.delete(x_data_condition,list(todel),axis=1)\\ntodel=set()\\nfor i in range(x_data_condition.shape[1]):\\n    for j in range(i+1,x_data_condition.shape[1]):\\n        if np.corrcoef(x_data_condition[~x_data_condition_nan][:,i],x_data_condition[~x_data_condition_nan][:,j])[1,0]>0.9:\\n            todel.add(i)\\n            todel.add(j)\\nx_data_condition_nan=np.any(np.isnan(x_data_condition),axis=1)  \\nnp.linalg.matrix_rank(x_data_condition[~x_data_condition_nan]),x_data_condition.shape[1]\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "x_data_condition=np.delete(x_data_condition,list(todel),axis=1)\n",
    "todel=set()\n",
    "for i in range(x_data_condition.shape[1]):\n",
    "    for j in range(i+1,x_data_condition.shape[1]):\n",
    "        if np.corrcoef(x_data_condition[~x_data_condition_nan][:,i],x_data_condition[~x_data_condition_nan][:,j])[1,0]>0.9:\n",
    "            todel.add(i)\n",
    "            todel.add(j)\n",
    "x_data_condition_nan=np.any(np.isnan(x_data_condition),axis=1)  \n",
    "np.linalg.matrix_rank(x_data_condition[~x_data_condition_nan]),x_data_condition.shape[1]\n",
    "\"\"\"            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "---------------------------------------------Regression---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "log.info_head(\"Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info('[{:3d}/{:3d}] {:10s} {:15s} {:5s} {:.5s}({}) {:.5s}'.format(\n",
    "                            0,\n",
    "                            len(aa_marker_name_list_aaonly),\n",
    "                            'ID',\n",
    "                            'residues',\n",
    "                            'n_obs',\n",
    "                            'chisq',\n",
    "                            'df',\n",
    "                            'P'\n",
    "                        ))\n",
    "assoc_result_list=[]\n",
    "\n",
    "for idx,aa_marker_name in enumerate(aa_marker_name_list_aaonly):\n",
    "    aa_marker_data=aa_marker_data_list[idx]\n",
    "    aa_marker_data_unique,aa_marker_data_onehot=marker_data_to_onehot(aa_marker_data)\n",
    "    aa_marker_data_unique_cut,aa_marker_data_onehot_cut=prepare_onehot(aa_marker_data_unique,aa_marker_data_onehot,set_nan=True,cut_mostfrequent=True)\n",
    "    \n",
    "    x_data_aa_marker=aa_marker_data_onehot_cut\n",
    "    x_data_aa_marker_nan=np.any(np.isnan(x_data_aa_marker),axis=1)\n",
    "    \n",
    "    x_data_nan=np.logical_or.reduce([x_data_covar_nan,x_data_condition_nan,x_data_aa_marker_nan])\n",
    "    \n",
    "    y_data=y_data_pheno\n",
    "    y_data_nan=y_data_pheno_nan    \n",
    "    x_y_data_nan=(x_data_nan)|(y_data_nan)\n",
    "\n",
    "\n",
    "    x_data_null=np.concatenate([x_data_intercept,x_data_covar,x_data_condition,x_data_aa_marker],axis=1)[~x_y_data_nan]\n",
    "    x_data_alt=np.concatenate([x_data_intercept,x_data_covar,x_data_condition],axis=1)[~x_y_data_nan]\n",
    "    y_data=y_data[~x_y_data_nan]\n",
    "    \n",
    "    \n",
    "    family=(sm.families.Gaussian() if assoc=='linear' else sm.families.Binomial())\n",
    "    model_null = sm.GLM(y_data,x_data_null, family=family,missing='raise')\n",
    "    model_alt = sm.GLM(y_data,x_data_alt, family=family,missing='raise')\n",
    "    \n",
    "    try:\n",
    "        result_alt = model_alt.fit()\n",
    "        result_null = model_null.fit()\n",
    "    except sm.tools.sm_exceptions.PerfectSeparationError as e:\n",
    "        nobs=np.nan\n",
    "        chisq_diff=np.nan\n",
    "        df_diff=np.nan\n",
    "        p_value=np.nan\n",
    "    else:\n",
    "        assert result_alt.nobs==result_null.nobs\n",
    "        nobs=result_alt.nobs\n",
    "        chisq_diff=2*(result_null.llf-result_alt.llf)\n",
    "        df_diff=result_null.df_model-result_alt.df_model\n",
    "        p_value=chi2.sf(chisq_diff,df_diff)        \n",
    "        #p_value=1 - chi2.cdf(chisq_diff,df_diff)\n",
    "\n",
    "    #print(result_alt.summary())\n",
    "    assoc_result={'idx':idx+1,\n",
    "                  'ID':aa_marker_name,\n",
    "                  'residues':','.join(aa_marker_data_unique),\n",
    "                  'n_obs':nobs,\n",
    "                  'chisq':chisq_diff,\n",
    "                  'df':df_diff,\n",
    "                'P':p_value}\n",
    "    \n",
    "    \n",
    "    assoc_result_list.append(assoc_result)\n",
    "    \n",
    "    log.info('[{:3d}/{:3d}] {:10s} {:15s} {:5f} {:.5f}({}) {:e}'.format(\n",
    "                                assoc_result['idx'],\n",
    "                                len(aa_marker_name_list_aaonly),\n",
    "                                assoc_result['ID'],\n",
    "                                assoc_result['residues'],\n",
    "                                assoc_result['n_obs'],\n",
    "                                assoc_result['chisq'],\n",
    "                                assoc_result['df'],\n",
    "                                assoc_result['P']\n",
    "                            ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(assoc_result_list)[['idx','ID','residues','n_obs','chisq','df','P']].to_csv(out+'.'+assoc,sep='\\t',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start time: Sat Feb 29 20:39:53 2020\n"
     ]
    }
   ],
   "source": [
    "log.info(\"End time: \"+time.strftime('%c', time.localtime(time.time())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
