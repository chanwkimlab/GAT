{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Alleic Association Test Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input/Output\n",
    "\n",
    "### Input: \n",
    "* .bgl.phased (You can convert plink file to .bgl.phased using Beagle 5)  (TODO: support for plink file if conditional analysis is not done)\n",
    "* .fam (the same as plink)\n",
    "* .phe (the same as plink)\n",
    "* regular expression for identifying multialleic marker\n",
    "* (optional) .covar (the same as plink)\n",
    "* (optional) .condition (the same as plink except that the )\n",
    "    \n",
    "### Ouput:\n",
    "* p-value for each merged marker (AA_A_1_Residue->AA_A_1) (HLA_A\\*--:-- ->HLA_A)  chisquare - degree freedom - p-value\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Functionality\n",
    "\n",
    "* support HLA gene multialleic Omnibus test\n",
    "\n",
    "Faster than R with same simulation settings and parameters\n",
    "* manually convert categorial input to onehot-encoded input\n",
    "* numpy use modules optimized for cpu(blas)\n",
    "\n",
    "* Integrity check between .fam, pedigree information from .aa\n",
    "* Simpler parameter parsing\n",
    "* can configure CPU thread limit\n",
    "\n",
    "\n",
    "https://stackoverflow.com/questions/48898712/very-slow-glm-logistic-regression-in-r"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "jupyter nbconvert omnibus_test.ipynb --to script\n",
    "\n",
    "example\n",
    "omnibus_test.py    --assoc linear \\\n",
    "    --out data/out_assoc/hba1c/step_02.omnibus \\\n",
    "    --pheno data/out_assoc/hba1c/phenotype.phe \\\n",
    "    --fam data/genotype/4_merge/KCHIP_HLA_SNP_1000G_merged.fam \\\n",
    "    --covar data/out_assoc/hba1c/step_02.omnibus.covar.temp \\\n",
    "    --aa data/out_assoc/hba1c/step_02.aa \\\n",
    "    --condition-list data/out_assoc/hba1c/step_02.omnibus.cond\\\n",
    "    \n",
    "numpy              1.17.4 \n",
    "pandas             0.25.3   \n",
    "scipy              1.3.2 \n",
    "\n",
    "statsmodels        0.10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "import socket\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--condition-list'], dest='condition_list', nargs=None, const=None, default=None, type=<function file_path at 0x7fc924154598>, choices=None, help='format is the same as plink', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dir_path(path):\n",
    "    if os.path.exists(os.path.dirname(path)):\n",
    "        return path\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError(f\"readable_dir:{path} is not a valid path\")\n",
    "\n",
    "def file_path(path):\n",
    "    if os.path.isfile(path):\n",
    "        return path\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError(f\"readable_dir:{path} is not a valid path\")\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Omnibus test')\n",
    "\n",
    "#required mode\n",
    "parser.add_argument('--assoc',choices=['linear','logistic'],required=True)\n",
    "\n",
    "#required output file\n",
    "parser.add_argument('--out', type=dir_path,required=True,help='output file prefix. (prefix.log, prefix.assoc will be generated)')\n",
    "\n",
    "#required input files\n",
    "parser.add_argument('--fam', type=file_path,required=True,help='plink fam file')\n",
    "parser.add_argument('--aa', type=file_path,required=True,help='AA call text file. For more information, refer to documentation. (like plink ped)')\n",
    "parser.add_argument('--pheno', type=file_path,required=True,help='format is the same as plink. Tab-delimited file without header of which the first and second columns is family and within-family IDs respectively and the third columns are pheotype')\n",
    "\n",
    "#optional\n",
    "parser.add_argument('--covar', type=file_path,help='format is the same as plink')\n",
    "parser.add_argument('--condition-list',type=file_path,help='format is the same as plink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug=False\n",
    "#debug=True\n",
    "\n",
    "if debug:\n",
    "    args=parser.parse_args('\\\n",
    "--assoc linear \\\n",
    "--out data/out_assoc/hba1c/step_02.omnibus \\\n",
    "--pheno data/out_assoc/hba1c/phenotype.phe \\\n",
    "--fam data/genotype/4_merge/KCHIP_HLA_SNP_1000G_merged.fam \\\n",
    "--covar data/out_assoc/hba1c/step_02.omnibus.covar.temp \\\n",
    "--aa data/out_assoc/hba1c/step_02.aa \\\n",
    "--condition-list data/out_assoc/hba1c/step_02.omnibus.cond\\\n",
    "'.split(' '))\n",
    "else:\n",
    "    args=parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger('logger')\n",
    "log.setLevel(logging.DEBUG)\n",
    "\n",
    "log_file_path=args.out+'.log'\n",
    "fileHandler = logging.FileHandler(log_file_path)\n",
    "streamHandler = logging.StreamHandler()\n",
    "\n",
    "formatter = logging.Formatter('%(message)s')\n",
    "fileHandler.setFormatter(formatter)\n",
    "streamHandler.setFormatter(formatter)\n",
    "\n",
    "log.addHandler(fileHandler)\n",
    "log.addHandler(streamHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info_head=lambda x: log.info('-'*int((100-len(x))/2)+x+'-'*int((100-len(x))/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info_head(\"**********************************************************\")\n",
    "log.info(\"* Amino Acid Association Test (Omnibus Test)\")\n",
    "log.info(\"* version 1.0\")\n",
    "log.info(\"* (C) 2020-, Seoul National University\")\n",
    "log.info(\"* Amino Acid Association Test (Omnibus Test)\")\n",
    "log.info(\"* Please report bugs to: Chanwoo Kim <ch6845@snu.ac.kr>\")\n",
    "log.info_head(\"**********************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start time: Sat Feb 29 20:39:53 2020\n"
     ]
    }
   ],
   "source": [
    "log.info(\"Start time: \"+time.strftime('%c', time.localtime(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Working directory: /data/ch6845/MHC_phewas_testbench\n"
     ]
    }
   ],
   "source": [
    "log.info('Working directory: '+os.getcwd())\n",
    "log.info('Hostname: '+socket.gethostname())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameters\n",
      "--assoc linear\n",
      "--out data/out_assoc/hba1c/step_02.omnibus\n",
      "--fam data/genotype/4_merge/KCHIP_HLA_SNP_1000G_merged.fam\n",
      "--aa data/out_assoc/hba1c/step_02.aa\n",
      "--pheno data/out_assoc/hba1c/phenotype.phe\n",
      "--covar data/out_assoc/hba1c/step_02.omnibus.covar.temp\n",
      "--condition_list data/out_assoc/hba1c/step_02.omnibus.cond\n"
     ]
    }
   ],
   "source": [
    "log.info('Parameters\\n'+'\\n'.join(['--{} {}'.format(key,value) for key,value in vars(args).items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assoc=args.assoc\n",
    "out=args.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------Data Loading--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "log.info_head(\"Data Loading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parse input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fam=pd.read_csv(args.fam,header=None,sep=' ',names=['FID','IID','fID','mID','sex','pheno']).astype({'FID':str,'IID':str,'fID':str,'mID':str,'sex':int,'pheno':float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125673 samples (45647 males, 80026 females) loaded from data/genotype/4_merge/KCHIP_HLA_SNP_1000G_merged.fam\n"
     ]
    }
   ],
   "source": [
    "log.info(\"{} samples ({} males, {} females) loaded from {}\".format(fam.shape[0],(fam['sex']==1).sum(),(fam['sex']==2).sum(),args.fam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_IID_list=None\n",
    "aa_sex_list=None\n",
    "aa_marker_name_list=[]\n",
    "aa_marker_data_list=[]\n",
    "with open(args.aa,'r') as f:\n",
    "    line_cnt=0\n",
    "    while True:\n",
    "        line=f.readline()            \n",
    "        if not line:\n",
    "            break        \n",
    "        line_cnt+=1\n",
    "        line_split=line.strip().split(' ')\n",
    "        line_type,line_id,line_data=line_split[0],line_split[1],line_split[2:]\n",
    "        if line_type=='P':\n",
    "            pass\n",
    "        elif line_type=='fID':\n",
    "            pass\n",
    "        elif line_type=='mID':\n",
    "            pass        \n",
    "        elif line_type=='I':        \n",
    "            aa_IID_list1=np.array([line_data[i] for i in range(0,len(line_data),2)])\n",
    "            aa_IID_list2=np.array([line_data[i+1] for i in range(0,len(line_data),2)])\n",
    "            if np.all(aa_IID_list1==aa_IID_list2):\n",
    "                aa_IID_list=aa_IID_list1\n",
    "            else:\n",
    "                raise\n",
    "        elif line_type=='C':\n",
    "            aa_sex_list1=np.array([line_data[i] for i in range(0,len(line_data),2)])\n",
    "            aa_sex_list2=np.array([line_data[i+1] for i in range(0,len(line_data),2)])\n",
    "            if np.all(aa_sex_list1==aa_sex_list2):\n",
    "                aa_sex_list=aa_sex_list1.astype(int)\n",
    "            else:\n",
    "                raise\n",
    "        elif line_type=='M':\n",
    "            aa_marker_name_list.append(line_id)\n",
    "            line_data=np.array([np.nan if x=='NA' else x for x in line_data])\n",
    "            aa_marker_data_list.append(line_data)\n",
    "        else:\n",
    "            print(line_type)\n",
    "            raise \n",
    "            \n",
    "aa_marker_name_list_aaonly=pd.Series(aa_marker_name_list)[pd.Series(aa_marker_name_list).str.slice(stop=3)=='AA_'].values            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "382 variants (361 AAs) loaded from data/out_assoc/hba1c/step_02.aa\n"
     ]
    }
   ],
   "source": [
    "log.info(\"{} variants ({} AAs) loaded from {}\".format(len(aa_marker_name_list),len(aa_marker_name_list_aaonly),args.aa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno=pd.read_csv(args.pheno,header=None,sep='\\t',names=['FID','IID','pheno'])\n",
    "pheno['pheno']=pheno['pheno'].replace(-9,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pheotype loaded from data/out_assoc/hba1c/phenotype.phe\n"
     ]
    }
   ],
   "source": [
    "log.info(\"pheotype loaded from {}\".format(args.pheno))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.assoc=='linear':\n",
    "    assert len(pheno['pheno'].unique())>2\n",
    "else:\n",
    "    assert np.all(np.isnan(pheno['pheno'])|(pheno['pheno']==1)|(pheno['pheno']==2))\n",
    "    pheno['pheno']=pheno['pheno']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125673 pheotype loaded from data/out_assoc/hba1c/phenotype.phe\n",
      "Among them, valid: 56650, missing: 69023\n",
      "mean=5.644237 std=0.499977 median=5.600000 min=4.200000 max=8.000000\n"
     ]
    }
   ],
   "source": [
    "log.info(\"{} pheotype loaded from {}\".format(pheno.shape[0],args.pheno))\n",
    "log.info(\"Among them, valid: {}, missing: {}\".format((~pheno['pheno'].isnull()).sum(),pheno['pheno'].isnull().sum()))\n",
    "if assoc=='linear':\n",
    "    log.info(\"mean={:4f} std={:4f} median={:4f} min={:4f} max={:4f}\".format(pheno['pheno'].mean(),pheno['pheno'].std(),pheno['pheno'].median(),pheno['pheno'].min(),pheno['pheno'].max()))\n",
    "else:\n",
    "    log.info(\"case: {} / control: {}\".format((pheno['pheno']==1).sum(),(pheno['pheno']==0).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parse optional input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9 covariates loaded from data/out_assoc/hba1c/step_02.omnibus.covar.temp\n"
     ]
    }
   ],
   "source": [
    "if args.covar is None:\n",
    "    covar=fam.iloc[:,:2]\n",
    "else:\n",
    "    covar=pd.read_csv(args.covar,sep='\\t')\n",
    "    covar.columns=['FID','IID']+covar.columns[2:].tolist()\n",
    "    covar=covar.astype({'FID':str,'IID':str})\n",
    "    \n",
    "    covar.iloc[:,2:]=covar.iloc[:,2:].astype(float)\n",
    "    covar.iloc[:,2:]=covar.iloc[:,2:].replace(-9,np.nan)\n",
    "    \n",
    "    log.info(\"{} covariates loaded from {}\".format(len(covar.columns[2:]),args.covar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "77 conditions loaded from --condition-list data/out_assoc/hba1c/step_02.omnibus.cond\n",
      "AA_C_-15, AA_C_-17, AA_C_-9, AA_C_1, AA_C_103, AA_C_11, AA_C_113, AA_C_114, AA_C_116, AA_C_138, AA_C_14, AA_C_147, AA_C_152, AA_C_156, AA_C_16, AA_C_163, AA_C_173, AA_C_175, AA_C_177, AA_C_184, AA_C_194, AA_C_21, AA_C_211, AA_C_219, AA_C_24, AA_C_248, AA_C_253, AA_C_261, AA_C_267, AA_C_273, AA_C_275, AA_C_285, AA_C_295, AA_C_303, AA_C_304, AA_C_305, AA_C_306, AA_C_307, AA_C_321, AA_C_324, AA_C_326, AA_C_339, AA_C_35, AA_C_49, AA_C_6, AA_C_66, AA_C_73, AA_C_77, AA_C_80, AA_C_9, AA_C_90, AA_C_91, AA_C_94, AA_C_95, AA_C_97, AA_C_99, HLA_C*01:02, HLA_C*02:02, HLA_C*03:02, HLA_C*03:03, HLA_C*03:04, HLA_C*04:01, HLA_C*05:01, HLA_C*06:02, HLA_C*07:02, HLA_C*07:04, HLA_C*07:06, HLA_C*08:01, HLA_C*08:02, HLA_C*08:03, HLA_C*08:22, HLA_C*12:02, HLA_C*12:03, HLA_C*14:02, HLA_C*14:03, HLA_C*15:02, HLA_C*15:05\n"
     ]
    }
   ],
   "source": [
    "if args.condition_list is None:\n",
    "    condition_list=[]\n",
    "else:\n",
    "    with open(args.condition_list,'r') as f:\n",
    "        condition_list=f.read().strip().split('\\n')\n",
    "        if condition_list[0]=='':\n",
    "            condition_list=[]\n",
    "            log.warning(\"Empty --condition-list {}\".format(args.condition_list))\n",
    "        else:\n",
    "            log.info(\"{} conditions loaded from --condition-list {}\".format(len(condition_list),args.condition_list))\n",
    "            log.info(', '.join(condition_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check idx integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(fam['IID']==aa_IID_list)\n",
    "assert np.all(fam['sex']==aa_sex_list)\n",
    "assert len(aa_marker_name_list)==len(aa_marker_data_list)\n",
    "\n",
    "assert np.all(fam['IID']==covar['IID'])\n",
    "assert len(set(condition_list).difference(set(aa_marker_name_list)))==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-------------------------------Checking missing values(observations)-------------------------------\n"
     ]
    }
   ],
   "source": [
    "log.info_head(\"Checking missing values(observations)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marker_data_to_onehot(aa_marker_data):\n",
    "    \n",
    "    aa_marker_data_unique=np.unique(aa_marker_data)\n",
    "    aa_marker_data_unique_nonan=aa_marker_data_unique[aa_marker_data_unique!='nan'].tolist()\n",
    "    aa_marker_data_unique_nan=aa_marker_data_unique_nonan+['nan']\n",
    "    \n",
    "    aa_marker_data_int_nan=list(map(lambda x: aa_marker_data_unique_nan.index(x),aa_marker_data))\n",
    "    \n",
    "    aa_marker_data_onehot_nan=np.zeros((len(aa_marker_data),len(aa_marker_data_unique_nan)))\n",
    "    aa_marker_data_onehot_nan[np.arange(len(aa_marker_data)),aa_marker_data_int_nan]=1\n",
    "    aa_marker_data_onehot_nonan=aa_marker_data_onehot_nan[:,:-1]\n",
    "    \n",
    "    return aa_marker_data_unique_nonan,aa_marker_data_onehot_nonan\n",
    "\n",
    "def prepare_onehot(aa_marker_data_unique_nonan,aa_marker_data_onehot_nonan,set_nan=True,cut_mostfrequent=True):\n",
    "    assert len(aa_marker_data_unique_nonan)==aa_marker_data_onehot_nonan.shape[1]\n",
    "    assert np.isnan(aa_marker_data_onehot_nonan).sum()==0\n",
    "    assert (np.nan not in aa_marker_data_unique_nonan) and ('nan' not in aa_marker_data_unique_nonan)\n",
    "    \n",
    "    aa_marker_data_onehot_nonan_sumrow=np.sum(aa_marker_data_onehot_nonan,axis=1)\n",
    "    aa_marker_data_onehot_nonan_sumcol=np.sum(aa_marker_data_onehot_nonan,axis=0)\n",
    "    #print(aa_marker_data_onehot_nonan_sumcol,np.argmax(aa_marker_data_onehot_nonan_sumcol))\n",
    "    #print(aa_marker_data_onehot_nonan_sumrow.shape,aa_marker_data_onehot_nonan_sumcol.shape)\n",
    "    #print(np.argmax(aa_marker_data_onehot_nonan_sumcol))\n",
    "    if set_nan:\n",
    "        aa_marker_data_onehot_nonan[aa_marker_data_onehot_nonan_sumrow!=1,:]=np.nan\n",
    "    if cut_mostfrequent:\n",
    "        aa_marker_data_unique_nonan=np.delete(aa_marker_data_unique_nonan, np.argmax(aa_marker_data_onehot_nonan_sumcol))\n",
    "        aa_marker_data_onehot_nonan=np.delete(aa_marker_data_onehot_nonan, np.argmax(aa_marker_data_onehot_nonan_sumcol), axis=1)\n",
    "    return aa_marker_data_unique_nonan,aa_marker_data_onehot_nonan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_pheno=np.repeat(pheno['pheno'].values,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_pheno_nan=np.isnan(y_data_pheno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.var(y_data_pheno[~y_data_pheno_nan])==0:\n",
    "    log.error(\"No variance in y_data\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "missing values in y_data_pheno: 138046\n"
     ]
    }
   ],
   "source": [
    "log.info(\"missing values in y_data_pheno: {}\".format(y_data_pheno_nan.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_intercept=np.array([np.ones(2*fam.shape[0])]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_covar=np.repeat(covar.iloc[:,2:].values,2,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "missing values in x_data_covar: 0\n"
     ]
    }
   ],
   "source": [
    "x_data_covar_nan=np.any(np.isnan(x_data_covar),axis=1)\n",
    "log.info(\"missing values in x_data_covar: {}\".format(x_data_covar_nan.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_covar_varcheck=np.array([np.var(covar) for covar in x_data_covar[~x_data_covar_nan].transpose()])==0\n",
    "\n",
    "if np.any(x_data_covar_varcheck):\n",
    "    log.info(\"Removed covariates of no variance\"+\", \".join(covar.columns[2:][x_data_covar_varcheck].tolist()))\n",
    "    x_data_covar=np.delete(x_data_covar,np.arange(len(x_data_covar_varcheck))[x_data_covar_varcheck],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (x_data_covar.size!=0) and (np.linalg.matrix_rank(x_data_covar)<x_data_covar.shape[1]):\n",
    "    log.info(\"duplicated covariates were found. (rank(covariates)< # of covarirates))\")\n",
    "    #raise\n",
    "    #x_data_covar=np.delete(x_data_covar,np.arange(len(x_data_covar_varcheck))[x_data_covar_varcheck],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list=[x_data_intercept[:,0:0]]\n",
    "for aa_marker_name in condition_list:\n",
    "    aa_marker_data=aa_marker_data_list[aa_marker_name_list.index(aa_marker_name)]\n",
    "\n",
    "    aa_marker_data_unique,aa_marker_data_onehot=marker_data_to_onehot(aa_marker_data)\n",
    "    aa_marker_data_unique_cut,aa_marker_data_onehot_cut=prepare_onehot(aa_marker_data_unique,aa_marker_data_onehot,set_nan=True,cut_mostfrequent=True)        \n",
    "    temp_list.append(aa_marker_data_onehot_cut)\n",
    "    \n",
    "x_data_condition=np.concatenate(temp_list,axis=1)\n",
    "x_data_condition_nan=np.any(np.isnan(x_data_condition),axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "missing values in x_data_condition: 97\n"
     ]
    }
   ],
   "source": [
    "log.info(\"missing values in x_data_condition: {}\".format(x_data_condition_nan.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx_data_condition=np.delete(x_data_condition,list(todel),axis=1)\\ntodel=set()\\nfor i in range(x_data_condition.shape[1]):\\n    for j in range(i+1,x_data_condition.shape[1]):\\n        if np.corrcoef(x_data_condition[~x_data_condition_nan][:,i],x_data_condition[~x_data_condition_nan][:,j])[1,0]>0.9:\\n            todel.add(i)\\n            todel.add(j)\\nx_data_condition_nan=np.any(np.isnan(x_data_condition),axis=1)  \\nnp.linalg.matrix_rank(x_data_condition[~x_data_condition_nan]),x_data_condition.shape[1]\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "x_data_condition=np.delete(x_data_condition,list(todel),axis=1)\n",
    "todel=set()\n",
    "for i in range(x_data_condition.shape[1]):\n",
    "    for j in range(i+1,x_data_condition.shape[1]):\n",
    "        if np.corrcoef(x_data_condition[~x_data_condition_nan][:,i],x_data_condition[~x_data_condition_nan][:,j])[1,0]>0.9:\n",
    "            todel.add(i)\n",
    "            todel.add(j)\n",
    "x_data_condition_nan=np.any(np.isnan(x_data_condition),axis=1)  \n",
    "np.linalg.matrix_rank(x_data_condition[~x_data_condition_nan]),x_data_condition.shape[1]\n",
    "\"\"\"            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "---------------------------------------------Regression---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "log.info_head(\"Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info('[{:3d}/{:3d}] {:10s} {:15s} {:5s} {:.5s}({}) {:.5s}'.format(\n",
    "                            0,\n",
    "                            len(aa_marker_name_list_aaonly),\n",
    "                            'ID',\n",
    "                            'residues',\n",
    "                            'n_obs',\n",
    "                            'chisq',\n",
    "                            'df',\n",
    "                            'P'\n",
    "                        ))\n",
    "assoc_result_list=[]\n",
    "\n",
    "for idx,aa_marker_name in enumerate(aa_marker_name_list_aaonly):\n",
    "    aa_marker_data=aa_marker_data_list[idx]\n",
    "    aa_marker_data_unique,aa_marker_data_onehot=marker_data_to_onehot(aa_marker_data)\n",
    "    aa_marker_data_unique_cut,aa_marker_data_onehot_cut=prepare_onehot(aa_marker_data_unique,aa_marker_data_onehot,set_nan=True,cut_mostfrequent=True)\n",
    "    \n",
    "    x_data_aa_marker=aa_marker_data_onehot_cut\n",
    "    x_data_aa_marker_nan=np.any(np.isnan(x_data_aa_marker),axis=1)\n",
    "    \n",
    "    x_data_nan=np.logical_or.reduce([x_data_covar_nan,x_data_condition_nan,x_data_aa_marker_nan])\n",
    "    \n",
    "    y_data=y_data_pheno\n",
    "    y_data_nan=y_data_pheno_nan    \n",
    "    x_y_data_nan=(x_data_nan)|(y_data_nan)\n",
    "\n",
    "\n",
    "    x_data_null=np.concatenate([x_data_intercept,x_data_covar,x_data_condition,x_data_aa_marker],axis=1)[~x_y_data_nan]\n",
    "    x_data_alt=np.concatenate([x_data_intercept,x_data_covar,x_data_condition],axis=1)[~x_y_data_nan]\n",
    "    y_data=y_data[~x_y_data_nan]\n",
    "    \n",
    "    \n",
    "    family=(sm.families.Gaussian() if assoc=='linear' else sm.families.Binomial())\n",
    "    model_null = sm.GLM(y_data,x_data_null, family=family,missing='raise')\n",
    "    model_alt = sm.GLM(y_data,x_data_alt, family=family,missing='raise')\n",
    "    \n",
    "    try:\n",
    "        result_alt = model_alt.fit()\n",
    "        result_null = model_null.fit()\n",
    "    except sm.tools.sm_exceptions.PerfectSeparationError as e:\n",
    "        nobs=np.nan\n",
    "        chisq_diff=np.nan\n",
    "        df_diff=np.nan\n",
    "        p_value=np.nan\n",
    "    else:\n",
    "        assert result_alt.nobs==result_null.nobs\n",
    "        nobs=result_alt.nobs\n",
    "        chisq_diff=2*(result_null.llf-result_alt.llf)\n",
    "        df_diff=result_null.df_model-result_alt.df_model\n",
    "        p_value=chi2.sf(chisq_diff,df_diff)        \n",
    "        #p_value=1 - chi2.cdf(chisq_diff,df_diff)\n",
    "\n",
    "    #print(result_alt.summary())\n",
    "    assoc_result={'idx':idx+1,\n",
    "                  'ID':aa_marker_name,\n",
    "                  'residues':','.join(aa_marker_data_unique),\n",
    "                  'n_obs':nobs,\n",
    "                  'chisq':chisq_diff,\n",
    "                  'df':df_diff,\n",
    "                'P':p_value}\n",
    "    \n",
    "    \n",
    "    assoc_result_list.append(assoc_result)\n",
    "    \n",
    "    log.info('[{:3d}/{:3d}] {:10s} {:15s} {:5f} {:.5f}({}) {:e}'.format(\n",
    "                                assoc_result['idx'],\n",
    "                                len(aa_marker_name_list_aaonly),\n",
    "                                assoc_result['ID'],\n",
    "                                assoc_result['residues'],\n",
    "                                assoc_result['n_obs'],\n",
    "                                assoc_result['chisq'],\n",
    "                                assoc_result['df'],\n",
    "                                assoc_result['P']\n",
    "                            ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(assoc_result_list)[['idx','ID','residues','n_obs','chisq','df','P']].to_csv(out+'.'+assoc,sep='\\t',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start time: Sat Feb 29 20:39:53 2020\n"
     ]
    }
   ],
   "source": [
    "log.info(\"End time: \"+time.strftime('%c', time.localtime(time.time())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
